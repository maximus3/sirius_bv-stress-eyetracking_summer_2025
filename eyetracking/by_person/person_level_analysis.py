import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import (
    ttest_ind,
    mannwhitneyu,
)
import pathlib
import warnings
import argparse

# =============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –ö–û–ù–°–¢–ê–ù–¢–´
# =============================================================================

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
def parse_arguments():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(
        description="–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ª—é–¥–µ–π –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å—Ç—Ä–µ—Å—Å–∞",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "--data-file",
        type=str,
        default="eyetracking/by_person/data/trial.xls",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ –ª—é–¥—è–º",
    )

    parser.add_argument(
        "--results-dir",
        type=str,
        default="eyetracking/by_person/results",
        help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
    )

    parser.add_argument(
        "--show-plots",
        action="store_true",
        help="–û—Ç–æ–±—Ä–∞–∂–∞—Ç—å —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–æ–ª—å–∫–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å)",
    )

    parser.add_argument(
        "--exclude-participants",
        type=str,
        nargs="+",
        default=[],
        help="–°–ø–∏—Å–æ–∫ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1807AAA 1907TRE 1607OOO)",
    )

    return parser.parse_args()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–±—É–¥—É—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤)
DATA_FILE = None
RESULTS_DIR = None
SHOW_PLOTS = False
EXCLUDED_PARTICIPANTS = []

# –ü–æ—Ä–æ–≥–∏ –¥–ª—è –≥—Ä—É–ø–ø —Å—Ç—Ä–µ—Å—Å–∞
STRESS_THRESHOLD = 3  # –¢—Ä–∞–π–ª—ã 1-STRESS_THRESHOLD –±–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º

# –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
ALPHA_LEVEL = 0.05
MIN_SAMPLE_SIZE_WARNING = 30  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –Ω–∞–¥–µ–∂–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤

# –ü–æ—Ä–æ–≥–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ Cohen's d
EFFECT_SIZE_SMALL = 0.2
EFFECT_SIZE_MEDIUM = 0.5
EFFECT_SIZE_LARGE = 0.8

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
FIGURE_DPI = 300
COLORS_NO_STRESS = "#2E86C1"  # –°–∏–Ω–∏–π
COLORS_STRESS = "#E74C3C"  # –ö—Ä–∞—Å–Ω—ã–π

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
SHOW_STATISTICAL_WARNINGS = False

# –°–ª–æ–≤–∞—Ä—å —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
UNITS = {
    # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–∫—Å–∞—Ü–∏–π
    "AVERAGE_FIXATION_DURATION": "–º—Å",
    "MEDIAN_FIXATION_DURATION": "–º—Å",
    "SD_FIXATION_DURATION": "–º—Å",
    "FIXATION_DURATION_MAX": "–º—Å",
    "FIXATION_DURATION_MIN": "–º—Å",
    
    # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∞–∫–∫–∞–¥
    "AVERAGE_SACCADE_AMPLITUDE": "¬∞",
    "MEDIAN_SACCADE_AMPLITUDE": "¬∞",
    "SD_SACCADE_AMPLITUDE": "¬∞",
    
    # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ—Ä–≥–∞–Ω–∏–π
    "AVERAGE_BLINK_DURATION": "–º—Å",
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑—Ä–∞—á–∫–∞
    "PUPIL_SIZE_MAX": "—É.–µ.",
    "PUPIL_SIZE_MEAN": "—É.–µ.",
    "PUPIL_SIZE_MIN": "—É.–µ.",
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–Ω–∞ —Å–ª–æ–≤–æ)
    "DURATION_PER_WORD": "–º—Å/—Å–ª–æ–≤–æ",
    "FIXATIONS_PER_WORD": "–µ–¥/—Å–ª–æ–≤–æ",
    "SACCADES_PER_WORD": "–µ–¥/—Å–ª–æ–≤–æ",
    "BLINKS_PER_WORD": "–µ–¥/—Å–ª–æ–≤–æ",
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–≤ —Å–µ–∫—É–Ω–¥—É)
    "FIXATIONS_PER_SECOND": "–µ–¥/—Å",
    "SACCADES_PER_SECOND": "–µ–¥/—Å",
    "BLINKS_PER_SECOND": "–µ–¥/—Å",
    
    # –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–∫—Å—Ç–∞
    "TEXT_COVERAGE_PERCENT": "%",
    "REVISITED_WORDS_PERCENT": "%",
    
    # –í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã
    "REGRESSIVE_SACCADES": "–µ–¥.",
    "REGRESSIVE_SACCADES_PER_WORD": "–µ–¥/—Å–ª–æ–≤–æ",
    "REGRESSIVE_SACCADES_PER_SECOND": "–µ–¥/—Å",
    "REGRESSIVE_SACCADES_PERCENT": "%",
}

# =============================================================================

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ warnings
if not SHOW_STATISTICAL_WARNINGS:
    warnings.filterwarnings("ignore")
    # –ü–æ–¥–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ matplotlib warnings
    warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")
    warnings.filterwarnings("ignore", message=".*labels.*parameter.*boxplot.*")
    warnings.filterwarnings("ignore", message=".*Glyph.*missing from font.*")
    plt.set_loglevel("WARNING")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –∫—Ä–∞—Å–∏–≤—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
plt.style.use("seaborn-v0_8")
plt.rcParams["font.family"] = ["DejaVu Sans"]
plt.rcParams["font.size"] = 12
plt.rcParams["axes.titlesize"] = 14
plt.rcParams["axes.labelsize"] = 12


def ensure_results_directory():
    """–°–æ–∑–¥–∞–µ—Ç –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
    if not pathlib.Path(RESULTS_DIR).exists():
        pathlib.Path(RESULTS_DIR).mkdir(parents=True, exist_ok=True)
        print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ '{RESULTS_DIR}' –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤")
    else:
        print(f"üìÅ –ü–∞–ø–∫–∞ '{RESULTS_DIR}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")


def show_plot_conditionally():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ SHOW_PLOTS"""
    if SHOW_PLOTS:
        plt.show()
    else:
        plt.close()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∏–≥—É—Ä—É –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏


def validate_sample_size(n, analysis_name="–∞–Ω–∞–ª–∏–∑"):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –∏ –≤—ã–¥–∞–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è"""
    if n < MIN_SAMPLE_SIZE_WARNING:
        print(f"‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ ({n}) –¥–ª—è {analysis_name} –º–µ–Ω—å—à–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–≥–æ ({MIN_SAMPLE_SIZE_WARNING})")
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã–º–∏")
        return False
    return True


def apply_bonferroni_correction(p_values, alpha=ALPHA_LEVEL):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–æ–ø—Ä–∞–≤–∫—É Bonferroni –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π"""
    n_tests = len(p_values)
    corrected_alpha = alpha / n_tests
    significant_count = sum(1 for p in p_values if p < corrected_alpha)
    
    print(f"üìä –ü–û–ü–†–ê–í–ö–ê BONFERRONI:")
    print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤: {n_tests}")
    print(f"   ‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π Œ±: {alpha}")
    print(f"   ‚Ä¢ –°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Œ±: {corrected_alpha:.4f}")
    print(f"   ‚Ä¢ –ó–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {significant_count}/{n_tests}")
    
    return corrected_alpha, significant_count


def get_phase_color(phase_name):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ü–≤–µ—Ç –¥–ª—è —Ñ–∞–∑—ã"""
    if "baseline" in phase_name:
        return COLORS_NO_STRESS
    elif "stress" in phase_name:
        return COLORS_STRESS
    else:
        return "#95A5A6"  # –°–µ—Ä—ã–π –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ñ–∞–∑


def interpret_effect_size_with_warnings(cohens_d, p_value, n_total, variable_name):
    """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏ –æ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏"""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞
    if abs(cohens_d) < EFFECT_SIZE_SMALL:
        effect_size = "–º–∞–ª—ã–π"
    elif abs(cohens_d) < EFFECT_SIZE_MEDIUM:
        effect_size = "—Å—Ä–µ–¥–Ω–∏–π"
    elif abs(cohens_d) < EFFECT_SIZE_LARGE:
        effect_size = "–±–æ–ª—å—à–æ–π"
    else:
        effect_size = "–æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å
    is_significant = p_value < ALPHA_LEVEL
    is_reliable_sample = n_total >= MIN_SAMPLE_SIZE_WARNING
    
    interpretation = f"d = {cohens_d:.3f} ({effect_size})"
    
    if not is_significant:
        interpretation += " ‚ö†Ô∏è –ù–ï–ó–ù–ê–ß–ò–ú–û"
        if not is_reliable_sample:
            interpretation += " + –ù–ï–ù–ê–î–ï–ñ–ù–û (–º–∞–ª–∞—è –≤—ã–±–æ—Ä–∫–∞)"
    elif not is_reliable_sample:
        interpretation += " ‚ö†Ô∏è –ù–ï–ù–ê–î–ï–ñ–ù–û (–º–∞–ª–∞—è –≤—ã–±–æ—Ä–∫–∞)"
    
    return interpretation


def count_regressive_saccades(sequence_data):
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã—Ö —Å–∞–∫–∫–∞–¥ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ñ–∏–∫—Å–∞—Ü–∏–π.
    
    –í–æ–∑–≤—Ä–∞—Ç–Ω–∞—è —Å–∞–∫–∫–∞–¥–∞ - —ç—Ç–æ –∫–æ–≥–¥–∞ —É—á–∞—Å—Ç–Ω–∏–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∫ —Ä–∞–Ω–µ–µ –ø–æ—Å–µ—â–µ–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –∏–Ω—Ç–µ—Ä–µ—Å–∞.
    –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ [1, 2, 3, 2, 4, 5, 3] –µ—Å—Ç—å 2 –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã:
    - –≤–æ–∑–≤—Ä–∞—Ç –∫ 2 (–ø–æ—Å–ª–µ –ø–æ—Å–µ—â–µ–Ω–∏—è 3)
    - –≤–æ–∑–≤—Ä–∞—Ç –∫ 3 (–ø–æ—Å–ª–µ –ø–æ—Å–µ—â–µ–Ω–∏—è 5)
    
    Args:
        sequence_data: –î–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π, —Å–ø–∏—Å–∫–æ–º –∏–ª–∏ NaN)
        
    Returns:
        int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã—Ö —Å–∞–∫–∫–∞–¥
    """
    if pd.isna(sequence_data) or sequence_data == '.' or sequence_data == '':
        return 0
    
    try:
        # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ —Å–ø–∏—Å–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if isinstance(sequence_data, list):
            sequence = sequence_data
        else:
            # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞, –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å–ø–∏—Å–æ–∫
            # –£–±–∏—Ä–∞–µ–º –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —Å–∫–æ–±–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∑–∞–ø—è—Ç—ã–º
            sequence_str = str(sequence_data).strip('[]')
            sequence = [int(x.strip()) for x in sequence_str.split(',') if x.strip().isdigit()]
        
        if len(sequence) < 2:
            return 0
        
        regressive_count = 0
        visited_positions = set()
        
        for i, current_word in enumerate(sequence):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º 0 (–æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤–∑–≥–ª—è–¥ –±—ã–ª –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏)
            if current_word == 0:
                continue
                
            # –ï—Å–ª–∏ —Ç–µ–∫—É—â–µ–µ —Å–ª–æ–≤–æ —É–∂–µ –±—ã–ª–æ –ø–æ—Å–µ—â–µ–Ω–æ —Ä–∞–Ω–µ–µ, —ç—Ç–æ –≤–æ–∑–≤—Ä–∞—Ç–Ω–∞—è —Å–∞–∫–∫–∞–¥–∞
            if current_word in visited_positions:
                regressive_count += 1
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–ª–æ–≤–æ –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø–æ—Å–µ—â–µ–Ω–Ω—ã—Ö
                visited_positions.add(current_word)
        
        return regressive_count
        
    except (ValueError, AttributeError, TypeError):
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
        return 0


def load_person_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –ª—é–¥—è–º"""
    print("üìÇ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ü–û –õ–Æ–î–Ø–ú...")
    
    # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º —Ñ–∞–π–ª–µ - header=0 –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Ç–æ—Ä—É—é —Å—Ç—Ä–æ–∫—É
    data = pd.read_csv(DATA_FILE, sep="\t", encoding="utf-16", header=0)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –∏ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ (–∫–∞–∫ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º —Ñ–∞–π–ª–µ)
    data = data.iloc[1:].reset_index(drop=True)
    
    print(f"   ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(data)}")
    print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫: {len(data.columns)}")
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–∞–ø—è—Ç—ã–µ –≤ —Ç–æ—á–∫–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    numeric_columns = [
        'AVERAGE_BLINK_DURATION', 'BLINK_COUNT', 'AVERAGE_FIXATION_DURATION',
        'MEDIAN_FIXATION_DURATION', 'SD_FIXATION_DURATION', 'FIXATION_DURATION_MAX',
        'FIXATION_DURATION_MIN', 'FIXATION_COUNT', 'AVERAGE_SACCADE_AMPLITUDE',
        'MEDIAN_SACCADE_AMPLITUDE', 'SD_SACCADE_AMPLITUDE', 'SACCADE_COUNT',
        'DURATION', 'PUPIL_SIZE_MAX', 'PUPIL_SIZE_MEAN', 'PUPIL_SIZE_MIN',
        'VISITED_INTEREST_AREA_COUNT', 'IA_COUNT', 'RUN_COUNT', 'SAMPLE_COUNT'
    ]
    
    for col in numeric_columns:
        if col in data.columns:
            data[col] = pd.to_numeric(
                data[col].astype(str).str.replace(",", "."), errors="coerce"
            )
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º INDEX –≤ —á–∏—Å–ª–æ–≤–æ–π
    data['INDEX'] = pd.to_numeric(data['INDEX'], errors='coerce')
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–∫–∞–∫ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º —Ñ–∞–π–ª–µ)
    print("   ‚Ä¢ –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫...")
    
    # 1. –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –æ–¥–Ω–æ —Å–ª–æ–≤–æ (–º—Å/—Å–ª–æ–≤–æ)
    data['DURATION_PER_WORD'] = data['DURATION'] / data['IA_COUNT']
    
    # 2. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–∫—Å–∞—Ü–∏–π –Ω–∞ –æ–¥–Ω–æ —Å–ª–æ–≤–æ
    data['FIXATIONS_PER_WORD'] = data['FIXATION_COUNT'] / data['IA_COUNT']
    
    # 3. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–∫–∫–∞–¥ –Ω–∞ –æ–¥–Ω–æ —Å–ª–æ–≤–æ
    data['SACCADES_PER_WORD'] = data['SACCADE_COUNT'] / data['IA_COUNT']
    
    # 4. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ—Ä–≥–∞–Ω–∏–π –Ω–∞ –æ–¥–Ω–æ —Å–ª–æ–≤–æ
    data['BLINKS_PER_WORD'] = data['BLINK_COUNT'] / data['IA_COUNT']
    
    # 5. –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–∫—Å—Ç–∞ (% –ø–æ—Å–µ—â–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞)
    data['TEXT_COVERAGE_PERCENT'] = (data['VISITED_INTEREST_AREA_COUNT'] / data['IA_COUNT']) * 100
    
    # 6. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ—Å–µ—â–µ–Ω–∏–π —Å–ª–æ–≤
    data['REVISITED_WORDS'] = data['RUN_COUNT'] - data['VISITED_INTEREST_AREA_COUNT']
    
    # 7. –ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ—Å–µ—â–µ–Ω–∏–π –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤
    data['REVISITED_WORDS_PERCENT'] = (data['REVISITED_WORDS'] / data['IA_COUNT']) * 100
    
    # 8. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–∫—Å–∞—Ü–∏–π –≤ —Å–µ–∫—É–Ω–¥—É
    data['FIXATIONS_PER_SECOND'] = data['FIXATION_COUNT'] / (data['DURATION'] / 1000)
    
    # 9. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–∫–∫–∞–¥ –≤ —Å–µ–∫—É–Ω–¥—É
    data['SACCADES_PER_SECOND'] = data['SACCADE_COUNT'] / (data['DURATION'] / 1000)
    
    # 10. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ—Ä–≥–∞–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É
    data['BLINKS_PER_SECOND'] = data['BLINK_COUNT'] / (data['DURATION'] / 1000)
    
    # 11. –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã—Ö —Å–∞–∫–∫–∞–¥
    print("   ‚Ä¢ –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã—Ö —Å–∞–∫–∫–∞–¥...")
    data['REGRESSIVE_SACCADES'] = data['INTEREST_AREA_FIXATION_SEQUENCE'].apply(count_regressive_saccades)
    
    # 12. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã—Ö —Å–∞–∫–∫–∞–¥ –Ω–∞ —Å–ª–æ–≤–æ
    data['REGRESSIVE_SACCADES_PER_WORD'] = data['REGRESSIVE_SACCADES'] / data['IA_COUNT']
    
    # 13. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã—Ö —Å–∞–∫–∫–∞–¥ –≤ —Å–µ–∫—É–Ω–¥—É
    data['REGRESSIVE_SACCADES_PER_SECOND'] = data['REGRESSIVE_SACCADES'] / (data['DURATION'] / 1000)
    
    # 14. –ü—Ä–æ—Ü–µ–Ω—Ç –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã—Ö —Å–∞–∫–∫–∞–¥ –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∞–∫–∫–∞–¥
    data['REGRESSIVE_SACCADES_PERCENT'] = (data['REGRESSIVE_SACCADES'] / data['SACCADE_COUNT']) * 100
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —É—Å–ª–æ–≤–∏–µ–º (—Å—Ç—Ä–µ—Å—Å/–±–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞)
    data['condition'] = data['INDEX'].apply(lambda x: 'stress' if x > STRESS_THRESHOLD else 'no_stress')
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —Ñ–∞–∑–æ–π
    data['phase'] = data['INDEX'].apply(lambda x: f"trial_{x}")
    
    # –ò—Å–∫–ª—é—á–∞–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
    if EXCLUDED_PARTICIPANTS:
        initial_participants = data['RECORDING_SESSION_LABEL'].nunique()
        data = data[~data['RECORDING_SESSION_LABEL'].isin(EXCLUDED_PARTICIPANTS)]
        remaining_participants = data['RECORDING_SESSION_LABEL'].nunique()
        excluded_count = initial_participants - remaining_participants
        print(f"   ‚Ä¢ –ò—Å–∫–ª—é—á–µ–Ω–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {excluded_count} ({', '.join(EXCLUDED_PARTICIPANTS)})")
    
    print(f"   ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {data['RECORDING_SESSION_LABEL'].nunique()}")
    print(f"   ‚Ä¢ –¢—Ä–∞–π–ª–æ–≤ –Ω–∞ —É—á–∞—Å—Ç–Ω–∏–∫–∞: {data.groupby('RECORDING_SESSION_LABEL').size().iloc[0]}")
    print(f"   ‚Ä¢ –£—Å–ª–æ–≤–∏—è: {data['condition'].value_counts().to_dict()}")
    
    return data


def analyze_person_level_differences(data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ª—é–¥–µ–π"""
    print("\nüî¨ –ê–ù–ê–õ–ò–ó –†–ê–ó–õ–ò–ß–ò–ô –ú–ï–ñ–î–£ –£–°–õ–û–í–ò–Ø–ú–ò (–£–†–û–í–ï–ù–¨ –õ–Æ–î–ï–ô)...")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º –∏ —É—Å–ª–æ–≤–∏—è–º
    person_conditions = data.groupby(['RECORDING_SESSION_LABEL', 'condition']).agg({
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–∫—Å–∞—Ü–∏–π
        'AVERAGE_FIXATION_DURATION': 'mean',
        'MEDIAN_FIXATION_DURATION': 'mean',
        'SD_FIXATION_DURATION': 'mean',
        'FIXATION_DURATION_MAX': 'mean',
        'FIXATION_DURATION_MIN': 'mean',
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∞–∫–∫–∞–¥
        'AVERAGE_SACCADE_AMPLITUDE': 'mean',
        'MEDIAN_SACCADE_AMPLITUDE': 'mean',
        'SD_SACCADE_AMPLITUDE': 'mean',
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ—Ä–≥–∞–Ω–∏–π
        'AVERAGE_BLINK_DURATION': 'mean',
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑—Ä–∞—á–∫–∞
        'PUPIL_SIZE_MAX': 'mean',
        'PUPIL_SIZE_MEAN': 'mean',
        'PUPIL_SIZE_MIN': 'mean',
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–Ω–∞ —Å–ª–æ–≤–æ)
        'DURATION_PER_WORD': 'mean',
        'FIXATIONS_PER_WORD': 'mean',
        'SACCADES_PER_WORD': 'mean',
        'BLINKS_PER_WORD': 'mean',
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–≤ —Å–µ–∫—É–Ω–¥—É)
        'FIXATIONS_PER_SECOND': 'mean',
        'SACCADES_PER_SECOND': 'mean',
        'BLINKS_PER_SECOND': 'mean',
        
        # –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–∫—Å—Ç–∞
        'TEXT_COVERAGE_PERCENT': 'mean',
        'REVISITED_WORDS_PERCENT': 'mean',
        
        # –í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã
        'REGRESSIVE_SACCADES': 'mean',
        'REGRESSIVE_SACCADES_PER_WORD': 'mean',
        'REGRESSIVE_SACCADES_PER_SECOND': 'mean',
        'REGRESSIVE_SACCADES_PERCENT': 'mean'
    }).reset_index()
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –≥—Ä—É–ø–ø—ã
    no_stress_data = person_conditions[person_conditions['condition'] == 'no_stress']
    stress_data = person_conditions[person_conditions['condition'] == 'stress']
    
    print(f"   ‚Ä¢ –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –≤ –≥—Ä—É–ø–ø–µ –±–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞: {len(no_stress_data)}")
    print(f"   ‚Ä¢ –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –≤ –≥—Ä—É–ø–ø–µ —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º: {len(stress_data)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏
    validate_sample_size(len(no_stress_data), "–≥—Ä—É–ø–ø–∞ –±–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞")
    validate_sample_size(len(stress_data), "–≥—Ä—É–ø–ø–∞ —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å
    results = []
    measure_names = [
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–∫—Å–∞—Ü–∏–π
        'AVERAGE_FIXATION_DURATION', 'MEDIAN_FIXATION_DURATION', 'SD_FIXATION_DURATION',
        'FIXATION_DURATION_MAX', 'FIXATION_DURATION_MIN',
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∞–∫–∫–∞–¥
        'AVERAGE_SACCADE_AMPLITUDE', 'MEDIAN_SACCADE_AMPLITUDE', 'SD_SACCADE_AMPLITUDE',
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ—Ä–≥–∞–Ω–∏–π
        'AVERAGE_BLINK_DURATION',
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑—Ä–∞—á–∫–∞
        'PUPIL_SIZE_MAX', 'PUPIL_SIZE_MEAN', 'PUPIL_SIZE_MIN',
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–Ω–∞ —Å–ª–æ–≤–æ)
        'DURATION_PER_WORD', 'FIXATIONS_PER_WORD', 'SACCADES_PER_WORD', 'BLINKS_PER_WORD',
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–≤ —Å–µ–∫—É–Ω–¥—É)
        'FIXATIONS_PER_SECOND', 'SACCADES_PER_SECOND', 'BLINKS_PER_SECOND',
        
        # –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–∫—Å—Ç–∞
        'TEXT_COVERAGE_PERCENT', 'REVISITED_WORDS_PERCENT',
        
        # –í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã
        'REGRESSIVE_SACCADES', 'REGRESSIVE_SACCADES_PER_WORD', 
        'REGRESSIVE_SACCADES_PER_SECOND', 'REGRESSIVE_SACCADES_PERCENT'
    ]
    
    for measure in measure_names:
        # –£–¥–∞–ª—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
        no_stress_clean = no_stress_data[measure].dropna()
        stress_clean = stress_data[measure].dropna()
        
        if len(no_stress_clean) == 0 or len(stress_clean) == 0:
            print(f"   ‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω {measure}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö")
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å
        try:
            from scipy.stats import shapiro
            _, p_no_stress = shapiro(no_stress_clean)
            _, p_stress = shapiro(stress_clean)
            normal_distribution = p_no_stress > 0.05 and p_stress > 0.05
        except:
            normal_distribution = False
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–µ—Å—Ç
        if normal_distribution:
            statistic, p_value = ttest_ind(no_stress_clean, stress_clean)
            test_name = "t-–∫—Ä–∏—Ç–µ—Ä–∏–π –°—Ç—å—é–¥–µ–Ω—Ç–∞"
        else:
            statistic, p_value = mannwhitneyu(no_stress_clean, stress_clean, alternative='two-sided')
            test_name = "–∫—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏"
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞
        pooled_std = np.sqrt(((len(no_stress_clean) - 1) * no_stress_clean.var() + 
                             (len(stress_clean) - 1) * stress_clean.var()) / 
                            (len(no_stress_clean) + len(stress_clean) - 2))
        cohens_d = (no_stress_clean.mean() - stress_clean.mean()) / pooled_std
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
        if no_stress_clean.mean() != 0:
            percent_change = ((stress_clean.mean() - no_stress_clean.mean()) / no_stress_clean.mean()) * 100
        else:
            percent_change = 0
        
        result = {
            'measure': measure,
            'test_name': test_name,
            'no_stress_mean': no_stress_clean.mean(),
            'no_stress_std': no_stress_clean.std(),
            'stress_mean': stress_clean.mean(),
            'stress_std': stress_clean.std(),
            'statistic': statistic,
            'p_value': p_value,
            'cohens_d': cohens_d,
            'percent_change': percent_change,
            'n_no_stress': len(no_stress_clean),
            'n_stress': len(stress_clean)
        }
        
        results.append(result)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        interpretation = interpret_effect_size_with_warnings(
            cohens_d, p_value, len(no_stress_clean) + len(stress_clean), measure
        )
        
        print(f"   ‚Ä¢ {measure}:")
        print(f"     –ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞: {no_stress_clean.mean():.2f}¬±{no_stress_clean.std():.2f}")
        print(f"     –°–æ —Å—Ç—Ä–µ—Å—Å–æ–º: {stress_clean.mean():.2f}¬±{stress_clean.std():.2f}")
        print(f"     –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {percent_change:+.1f}% | {interpretation}")
        print(f"     –¢–µ—Å—Ç: {test_name}, p = {p_value:.4f}")
    
    return results


def analyze_person_dynamics(data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∏–Ω–∞–º–∏–∫—É –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –ø–æ —Ç—Ä–∞–π–ª–∞–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞"""
    print("\nüìà –ê–ù–ê–õ–ò–ó –î–ò–ù–ê–ú–ò–ö–ò –ü–û –¢–†–ê–ô–õ–ê–ú...")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç—Ä–∞–π–ª–∞–º
    trial_stats = data.groupby('INDEX').agg({
        'AVERAGE_BLINK_DURATION': ['mean', 'std'],
        'BLINK_COUNT': ['mean', 'std'],
        'AVERAGE_FIXATION_DURATION': ['mean', 'std'],
        'MEDIAN_FIXATION_DURATION': ['mean', 'std'],
        'SD_FIXATION_DURATION': ['mean', 'std'],
        'FIXATION_DURATION_MAX': ['mean', 'std'],
        'FIXATION_DURATION_MIN': ['mean', 'std'],
        'FIXATION_COUNT': ['mean', 'std'],
        'AVERAGE_SACCADE_AMPLITUDE': ['mean', 'std'],
        'MEDIAN_SACCADE_AMPLITUDE': ['mean', 'std'],
        'SD_SACCADE_AMPLITUDE': ['mean', 'std'],
        'SACCADE_COUNT': ['mean', 'std'],
        'DURATION': ['mean', 'std'],
        'PUPIL_SIZE_MAX': ['mean', 'std'],
        'PUPIL_SIZE_MEAN': ['mean', 'std'],
        'PUPIL_SIZE_MIN': ['mean', 'std'],
        'VISITED_INTEREST_AREA_COUNT': ['mean', 'std'],
        'IA_COUNT': ['mean', 'std'],
        'RUN_COUNT': ['mean', 'std'],
        'SAMPLE_COUNT': ['mean', 'std']
    }).reset_index()
    
    # –£–ø—Ä–æ—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
    trial_stats.columns = ['INDEX'] + [f"{col[0]}_{col[1]}" for col in trial_stats.columns[1:]]
    
    print(f"   ‚Ä¢ –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç—Ä–∞–π–ª–æ–≤: {len(trial_stats)}")
    
    return trial_stats


def create_enhanced_trial_dynamics_visualization(data, key_measures):
    """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –¥–∏–Ω–∞–º–∏–∫–∏ –ø–æ —Ç—Ä–∞–π–ª–∞–º (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ comprehensive_eyetracking_analysis.py)"""
    print(f"\nüé® –°–û–ó–î–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ù–û–ì–û –ì–†–ê–§–ò–ö–ê –î–ò–ù–ê–ú–ò–ö–ò –ü–û –¢–†–ê–ô–õ–ê–ú")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à—É—é —Ñ–∏–≥—É—Ä—É –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–∞–π–ª–æ–≤
    fig, axes = plt.subplots(3, 3, figsize=(24, 18))
    axes = axes.flatten()
    
    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ñ–∞–∑ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ comprehensive_eyetracking_analysis.py)
    phase_colors = {
        "baseline_1": "#3498DB",  # –°–∏–Ω–∏–π
        "baseline_2": "#5DADE2",  # –°–≤–µ—Ç–ª–æ-—Å–∏–Ω–∏–π
        "baseline_3": "#85C1E9",  # –ï—â–µ —Å–≤–µ—Ç–ª–µ–µ —Å–∏–Ω–∏–π
        "stress_peak": "#E74C3C",  # –ö—Ä–∞—Å–Ω—ã–π (–ø–∏–∫)
        "stress_adapt": "#F1948A",  # –†–æ–∑–æ–≤—ã–π (–∞–¥–∞–ø—Ç–∞—Ü–∏—è)
        "stress_recovery": "#F8C471",  # –ñ–µ–ª—Ç—ã–π (–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ)
    }
    
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–∞–∑—ã —Ç—Ä–∞–π–ª–∞
    def get_trial_phase(trial_num):
        if trial_num <= 3:
            return f"baseline_{trial_num}"
        elif trial_num == 4:
            return "stress_peak"
        elif trial_num == 5:
            return "stress_adapt"
        else:
            return "stress_recovery"
    
    # –°–ª–æ–≤–∞—Ä—å —Å —Ä—É—Å—Å–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –º–µ—Ä
    measure_names_map = {
        "AVERAGE_FIXATION_DURATION": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–∫—Å–∞—Ü–∏–π (—Å—Ä–µ–¥–Ω—è—è)",
        "MEDIAN_FIXATION_DURATION": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–∫—Å–∞—Ü–∏–π (–º–µ–¥–∏–∞–Ω–∞)",
        "FIXATION_DURATION_MAX": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–∫—Å–∞—Ü–∏–π (–º–∞–∫—Å)",
        "AVERAGE_SACCADE_AMPLITUDE": "–ê–º–ø–ª–∏—Ç—É–¥–∞ —Å–∞–∫–∫–∞–¥ (—Å—Ä–µ–¥–Ω—è—è)",
        "MEDIAN_SACCADE_AMPLITUDE": "–ê–º–ø–ª–∏—Ç—É–¥–∞ —Å–∞–∫–∫–∞–¥ (–º–µ–¥–∏–∞–Ω–∞)",
        "AVERAGE_BLINK_DURATION": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ—Ä–≥–∞–Ω–∏–π",
        "PUPIL_SIZE_MEAN": "–†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞ (—Å—Ä–µ–¥–Ω–∏–π)",
        "PUPIL_SIZE_MAX": "–†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞ (–º–∞–∫—Å)",
        "DURATION_PER_WORD": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Å–ª–æ–≤–æ",
        "FIXATIONS_PER_WORD": "–§–∏–∫—Å–∞—Ü–∏–∏ –Ω–∞ —Å–ª–æ–≤–æ",
        "SACCADES_PER_WORD": "–°–∞–∫–∫–∞–¥—ã –Ω–∞ —Å–ª–æ–≤–æ",
        "FIXATIONS_PER_SECOND": "–§–∏–∫—Å–∞—Ü–∏–∏ –≤ —Å–µ–∫—É–Ω–¥—É",
        "SACCADES_PER_SECOND": "–°–∞–∫–∫–∞–¥—ã –≤ —Å–µ–∫—É–Ω–¥—É",
        "TEXT_COVERAGE_PERCENT": "–ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–∫—Å—Ç–∞ (%)",
        "REVISITED_WORDS_PERCENT": "–ü–æ–≤—Ç–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞ (%)",
        "REGRESSIVE_SACCADES": "–í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã",
        "REGRESSIVE_SACCADES_PERCENT": "–í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã (%)"
    }
    
    for i, measure in enumerate(key_measures[:9]):  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 9 –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è
        ax = axes[i]
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç—Ä–∞–π–ª–∞–º
        trial_means = data.groupby('INDEX')[measure].mean()
        trial_stds = data.groupby('INDEX')[measure].std()
        
        if len(trial_means) > 0:
            trials = sorted(trial_means.index)
            means = [trial_means[t] for t in trials]
            stds = [trial_stds[t] for t in trials]
            phases = [get_trial_phase(t) for t in trials]
            colors = [phase_colors.get(phase, "#95A5A6") for phase in phases]
            
            # –°–æ–∑–¥–∞–µ–º bar plot —Å —Ä–∞–∑–Ω—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏ –¥–ª—è —Ñ–∞–∑
            bars = ax.bar(
                trials,
                means,
                yerr=stds,
                capsize=5,
                color=colors,
                alpha=0.8,
                edgecolor="black",
                linewidth=1,
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é —Ç—Ä–µ–Ω–¥–∞
            ax.plot(trials, means, "k--", alpha=0.7, linewidth=2, marker="o", markersize=6)
            
            # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è —Ä–∞–∑–¥–µ–ª—è—é—â–∞—è —Ñ–∞–∑—ã
            ax.axvline(x=3.5, color="red", linestyle=":", linewidth=2, alpha=0.7)
            ax.text(
                3.5,
                max(means) * 0.9,
                "–ù–ê–ß–ê–õ–û\n–°–¢–†–ï–°–°–ê",
                ha="center",
                va="center",
                bbox=dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.3),
            )
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            measure_name = measure_names_map.get(measure, measure)
            ax.set_title(
                f"{measure_name}",
                fontweight="bold",
                fontsize=13,
            )
            
            # –ü–æ–¥–ø–∏—Å–∏ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ –±–∞—Ä–∞—Ö
            baseline_mean = np.mean([trial_means[t] for t in [1, 2, 3]])
            for j, (trial, mean_val) in enumerate(zip(trials, means)):
                if trial > 3:  # –¢–æ–ª—å–∫–æ –¥–ª—è —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö —Ç—Ä–∞–π–ª–æ–≤
                    change_pct = ((mean_val - baseline_mean) / baseline_mean) * 100
                    symbol = "‚Üó" if change_pct > 0 else "‚Üò"
                    ax.text(
                        trial,
                        mean_val + stds[j] + max(means) * 0.02,
                        f"{symbol}{abs(change_pct):.1f}%",
                        ha="center",
                        va="bottom",
                        fontweight="bold",
                        fontsize=10,
                    )
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Å–µ–π
            ax.set_xlabel("–ù–æ–º–µ—Ä —Ç—Ä–∞–π–ª–∞")
            unit = UNITS.get(measure, "")
            ax.set_ylabel(f"–ó–Ω–∞—á–µ–Ω–∏–µ, {unit}" if unit else "–ó–Ω–∞—á–µ–Ω–∏–µ")
            ax.set_xticks(trials)
            ax.grid(True, alpha=0.3)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–µ–Ω–¥—É —Ñ–∞–∑ (—Ç–æ–ª—å–∫–æ –Ω–∞ –ø–µ—Ä–≤–æ–º –≥—Ä–∞—Ñ–∏–∫–µ)
            if i == 0:
                legend_elements = []
                legend_labels = {
                    "baseline_1": "–ë–∞–∑–æ–≤–∞—è –ª–∏–Ω–∏—è",
                    "stress_peak": "–ü–∏–∫ —Å—Ç—Ä–µ—Å—Å–∞",
                    "stress_adapt": "–ê–¥–∞–ø—Ç–∞—Ü–∏—è",
                    "stress_recovery": "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
                }
                for phase, color in phase_colors.items():
                    if phase in legend_labels:
                        legend_elements.append(
                            plt.Rectangle((0, 0), 1, 1, facecolor=color, alpha=0.8)
                        )
                
                ax.legend(
                    legend_elements,
                    list(legend_labels.values()),
                    loc="upper right",
                    fontsize=9,
                )
    
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∏
    for i in range(9, len(axes)):
        fig.delaxes(axes[i])
    
    # –û–±—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    fig.suptitle(
        "üìä –î–ò–ù–ê–ú–ò–ö–ê –°–¢–†–ï–°–°–ê –ü–û –¢–†–ê–ô–õ–ê–ú (–£–†–û–í–ï–ù–¨ –õ–Æ–î–ï–ô)",
        fontsize=18,
        fontweight="bold",
        y=0.98,
    )
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.92)
    plt.savefig(
        f"{RESULTS_DIR}/person_level_dynamics.png", dpi=FIGURE_DPI, bbox_inches="tight"
    )
    show_plot_conditionally()


def create_key_dynamics_visualization(data):
    """
    –°–æ–∑–¥–∞–µ—Ç 3 –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–∞ —Å –¥–∏–Ω–∞–º–∏–∫–æ–π –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –ø–æ —Ç—Ä–∞–π–ª–∞–º.
    """
    print(f"\nüé® –°–û–ó–î–ê–ù–ò–ï –ì–†–ê–§–ò–ö–û–í –î–ò–ù–ê–ú–ò–ö–ò –ö–õ–Æ–ß–ï–í–´–• –ü–û–ö–ê–ó–ê–¢–ï–õ–ï–ô")
    print("=" * 50)
    
    # –ì—Ä—É–ø–ø—ã –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
    measure_groups = [
        # –ì—Ä–∞—Ñ–∏–∫ 1: –ß–∞—Å—Ç–æ—Ç–∞ –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–∫—Å–∞—Ü–∏–π
        {
            "measures": ["FIXATIONS_PER_SECOND", "AVERAGE_FIXATION_DURATION"],
            "title": "–§–∏–∫—Å–∞—Ü–∏–∏: —á–∞—Å—Ç–æ—Ç–∞ –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
            "colors": ["#2E86C1", "#E74C3C"],
            "names": ["–ß–∞—Å—Ç–æ—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–π (–µ–¥/—Å)", "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–∫—Å–∞—Ü–∏–π (–º—Å)"],
            "filename": "key_trial_dynamics_fixations.png"
        },
        # –ì—Ä–∞—Ñ–∏–∫ 2: –ß–∞—Å—Ç–æ—Ç–∞ –∏ –∞–º–ø–ª–∏—Ç—É–¥–∞ —Å–∞–∫–∫–∞–¥
        {
            "measures": ["SACCADES_PER_SECOND", "AVERAGE_SACCADE_AMPLITUDE"], 
            "title": "–°–∞–∫–∫–∞–¥—ã: —á–∞—Å—Ç–æ—Ç–∞ –∏ –∞–º–ø–ª–∏—Ç—É–¥–∞",
            "colors": ["#28B463", "#F39C12"],
            "names": ["–ß–∞—Å—Ç–æ—Ç–∞ —Å–∞–∫–∫–∞–¥ (–µ–¥/—Å)", "–ê–º–ø–ª–∏—Ç—É–¥–∞ —Å–∞–∫–∫–∞–¥ (¬∞)"],
            "filename": "key_trial_dynamics_saccades.png"
        },
        # –ì—Ä–∞—Ñ–∏–∫ 3: –í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Å–ª–æ–≤–æ, —Ä–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞
        {
            "measures": ["REGRESSIVE_SACCADES", "DURATION_PER_WORD", "PUPIL_SIZE_MEAN"],
            "title": "–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏",
            "colors": ["#8E44AD", "#D35400", "#17A2B8"],
            "names": ["–í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã (–µ–¥)", "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Å–ª–æ–≤–æ (–º—Å)", "–†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞ (—É.–µ.)"],
            "filename": "key_trial_dynamics_complex.png"
        }
    ]
    
    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ñ–∞–∑
    phase_colors = {
        "baseline_1": "#3498DB",  # –°–∏–Ω–∏–π
        "baseline_2": "#5DADE2",  # –°–≤–µ—Ç–ª–æ-—Å–∏–Ω–∏–π
        "baseline_3": "#85C1E9",  # –ï—â–µ —Å–≤–µ—Ç–ª–µ–µ —Å–∏–Ω–∏–π
        "stress_peak": "#E74C3C",  # –ö—Ä–∞—Å–Ω—ã–π (–ø–∏–∫)
        "stress_adapt": "#F1948A",  # –†–æ–∑–æ–≤—ã–π (–∞–¥–∞–ø—Ç–∞—Ü–∏—è)
        "stress_recovery": "#F8C471",  # –ñ–µ–ª—Ç—ã–π (–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ)
    }
    
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–∞–∑—ã —Ç—Ä–∞–π–ª–∞
    def get_trial_phase(trial_num):
        if trial_num <= 3:
            return f"baseline_{trial_num}"
        elif trial_num == 4:
            return "stress_peak"
        elif trial_num == 5:
            return "stress_adapt"
        else:
            return "stress_recovery"
    
    # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
    for group_idx, group_info in enumerate(measure_groups):
        print(f"   üìä –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ {group_idx + 1}/3: {group_info['title']}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–æ–≤
        n_measures = len(group_info["measures"])
        if n_measures == 2:
            fig, axes = plt.subplots(1, 2, figsize=(16, 6))
        else:  # n_measures == 3
            fig, axes = plt.subplots(1, 3, figsize=(20, 6))
        
        # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫, –¥–µ–ª–∞–µ–º axes —Å–ø–∏—Å–∫–æ–º
        if n_measures == 1:
            axes = [axes]
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è —Å–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫
        for measure_idx, measure in enumerate(group_info["measures"]):
            ax = axes[measure_idx]
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç—Ä–∞–π–ª–∞–º
            trial_means = data.groupby('INDEX')[measure].mean()
            
            if len(trial_means) > 0:
                trials = sorted(trial_means.index)
                values = [trial_means[t] for t in trials]
                phases = [get_trial_phase(t) for t in trials]
                
                # –°–æ–∑–¥–∞–µ–º –ª–∏–Ω–µ–π–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫
                line_color = group_info["colors"][measure_idx]
                ax.plot(trials, values, "o-", linewidth=3, markersize=8, 
                       color=line_color, label=group_info["names"][measure_idx])
                
                # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º —Ç–æ—á–∫–∏ –ø–æ —Ñ–∞–∑–∞–º
                for j, (trial, value, phase) in enumerate(zip(trials, values, phases)):
                    ax.scatter(
                        trial,
                        value,
                        s=150,
                        c=phase_colors.get(phase, "#95A5A6"),
                        edgecolor=line_color,
                        linewidth=3,
                        zorder=5,
                    )
                
                # –ü–æ–¥–ø–∏—Å–∏ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ–¥ —Ç–æ—á–∫–∞–º–∏ (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç—Ä–∞–π–ª–∞ 3)
                trial3_mean = trial_means[3] if 3 in trial_means else np.mean([trial_means[t] for t in [1, 2, 3]])
                values_range = max(values) - min(values)
                for j, (trial, mean_val) in enumerate(zip(trials, values)):
                    if trial >= 4:  # –¢–æ–ª—å–∫–æ –¥–ª—è —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö —Ç—Ä–∞–π–ª–æ–≤ (4-6)
                        change_pct = ((mean_val - trial3_mean) / trial3_mean) * 100
                        symbol = "‚Üó" if change_pct > 0 else "‚Üò"
                        
                        ax.text(
                            trial,
                            mean_val - values_range * 0.08,
                            f"{symbol}{abs(change_pct):.1f}%",
                            ha="center",
                            va="top",
                            fontweight="bold",
                            fontsize=9,
                            bbox=dict(boxstyle="round,pad=0.2", facecolor="white", alpha=0.8),
                        )
                
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞
                ax.set_xlabel("–ù–æ–º–µ—Ä —Ç—Ä–∞–π–ª–∞", fontsize=11)
                unit = UNITS.get(measure, "")
                ax.set_ylabel(f"–ó–Ω–∞—á–µ–Ω–∏–µ, {unit}" if unit else "–ó–Ω–∞—á–µ–Ω–∏–µ", fontsize=11)
                ax.set_title(group_info["names"][measure_idx], fontweight="bold", fontsize=13)
                ax.set_xticks(trials)
                ax.grid(True, alpha=0.3)
                
                # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è —Ä–∞–∑–¥–µ–ª—è—é—â–∞—è —Ñ–∞–∑—ã
                ax.axvline(
                    x=STRESS_THRESHOLD + 0.5, color="red", linestyle="--", alpha=0.7, linewidth=2
                )
        
        # –û–±—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
        fig.suptitle(group_info["title"], fontweight="bold", fontsize=16)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.90)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–π –≥—Ä–∞—Ñ–∏–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
        filename = f"{RESULTS_DIR}/{group_info['filename']}"
        plt.savefig(filename, dpi=FIGURE_DPI, bbox_inches="tight")
        print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
        
        show_plot_conditionally()
    
    print(f"üìÅ –°–æ–∑–¥–∞–Ω–æ 3 –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–∞ —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –¥–∏–Ω–∞–º–∏–∫–∏")


def create_clean_stress_dynamics_visualization(data):
    """
    –°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –¥–∏–Ω–∞–º–∏–∫–∏ —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –∞–¥–∞–ø—Ç–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç—Ä–∞–π–ª–æ–≤ (1 –∏ 6).
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ —Ç—Ä–∞–π–ª—ã 2-5 –¥–ª—è –±–æ–ª–µ–µ —á–∏—Å—Ç–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ç—Ä–µ—Å—Å–æ–≤–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞.
    """
    print(f"\nüé® –°–û–ó–î–ê–ù–ò–ï –ì–†–ê–§–ò–ö–ê –î–ò–ù–ê–ú–ò–ö–ò –ë–ï–ó –ê–î–ê–ü–¢–ê–¶–ò–û–ù–ù–´–• –¢–†–ê–ô–õ–û–í")
    print("=" * 50)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ: –∏—Å–∫–ª—é—á–∞–µ–º —Ç—Ä–∞–π–ª—ã 1 –∏ 6
    clean_data = data[data['INDEX'].isin([2, 3, 4, 5])].copy()
    
    fig, axes = plt.subplots(2, 3, figsize=(24, 12))
    axes = axes.flatten()
    
    # –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    measures_for_clean_dynamics = [
        "FIXATIONS_PER_SECOND",
        "AVERAGE_FIXATION_DURATION", 
        "PUPIL_SIZE_MEAN",
        "SACCADES_PER_SECOND",
        "DURATION_PER_WORD",
        "REGRESSIVE_SACCADES",
    ]
    
    measure_names_map = {
        "FIXATIONS_PER_SECOND": "–ß–∞—Å—Ç–æ—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–π (–µ–¥/—Å)",
        "AVERAGE_FIXATION_DURATION": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–∫—Å–∞—Ü–∏–π (–º—Å)",
        "PUPIL_SIZE_MEAN": "–†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞ (—É.–µ.)",
        "SACCADES_PER_SECOND": "–ß–∞—Å—Ç–æ—Ç–∞ —Å–∞–∫–∫–∞–¥ (–µ–¥/—Å)",
        "DURATION_PER_WORD": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Å–ª–æ–≤–æ (–º—Å)",
        "REGRESSIVE_SACCADES": "–í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã (–µ–¥)",
    }
    
    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ñ–∞–∑ (—Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –∏ —Å—Ç—Ä–µ—Å—Å–æ–≤—ã–µ)
    phase_colors = {
        "baseline_2": "#3498DB",  # –°–∏–Ω–∏–π
        "baseline_3": "#5DADE2",  # –°–≤–µ—Ç–ª–æ-—Å–∏–Ω–∏–π
        "stress_peak": "#E74C3C",  # –ö—Ä–∞—Å–Ω—ã–π (–ø–∏–∫)
        "stress_adapt": "#F1948A",  # –†–æ–∑–æ–≤—ã–π (–∞–¥–∞–ø—Ç–∞—Ü–∏—è)
    }
    
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–∞–∑—ã —Ç—Ä–∞–π–ª–∞
    def get_trial_phase(trial_num):
        if trial_num == 2:
            return "baseline_2"
        elif trial_num == 3:
            return "baseline_3"
        elif trial_num == 4:
            return "stress_peak"
        else:  # trial_num == 5
            return "stress_adapt"
    
    for i, measure in enumerate(measures_for_clean_dynamics):
        ax = axes[i]
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç—Ä–∞–π–ª–∞–º
        trial_means = clean_data.groupby('INDEX')[measure].mean()
        trial_stds = clean_data.groupby('INDEX')[measure].std()
        
        if len(trial_means) > 0:
            trials = sorted(trial_means.index)
            means = [trial_means[t] for t in trials]
            stds = [trial_stds[t] for t in trials]
            phases = [get_trial_phase(t) for t in trials]
            colors = [phase_colors.get(phase, "#95A5A6") for phase in phases]
            
            # –°–æ–∑–¥–∞–µ–º bar plot —Å —Ä–∞–∑–Ω—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏ –¥–ª—è —Ñ–∞–∑
            bars = ax.bar(
                trials,
                means,
                yerr=stds,
                capsize=5,
                color=colors,
                alpha=0.8,
                edgecolor="black",
                linewidth=1,
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é —Ç—Ä–µ–Ω–¥–∞
            ax.plot(trials, means, "k--", alpha=0.7, linewidth=2, marker="o", markersize=6)
            
            # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è —Ä–∞–∑–¥–µ–ª—è—é—â–∞—è —Ñ–∞–∑—ã
            ax.axvline(x=3.5, color="red", linestyle=":", linewidth=2, alpha=0.7)
            ax.text(
                3.5,
                max(means) * 0.9,
                "–ù–ê–ß–ê–õ–û\n–°–¢–†–ï–°–°–ê",
                ha="center",
                va="center",
                bbox=dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.3),
            )
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            measure_name = measure_names_map.get(measure, measure)
            ax.set_title(
                f"{measure_name}\n(–ë–µ–∑ —Ç—Ä–∞–π–ª–æ–≤ 1 –∏ 6)",
                fontweight="bold",
                fontsize=12,
            )
            
            # –ü–æ–¥–ø–∏—Å–∏ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ –±–∞—Ä–∞—Ö
            baseline_mean = np.mean([trial_means[t] for t in [2, 3]])
            for j, (trial, mean_val) in enumerate(zip(trials, means)):
                if trial > 3:  # –¢–æ–ª—å–∫–æ –¥–ª—è —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö —Ç—Ä–∞–π–ª–æ–≤
                    change_pct = ((mean_val - baseline_mean) / baseline_mean) * 100
                    symbol = "‚Üó" if change_pct > 0 else "‚Üò"
                    ax.text(
                        trial,
                        mean_val + stds[j] + max(means) * 0.02,
                        f"{symbol}{abs(change_pct):.1f}%",
                        ha="center",
                        va="bottom",
                        fontweight="bold",
                        fontsize=10,
                    )
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Å–µ–π
            ax.set_xlabel("–ù–æ–º–µ—Ä —Ç—Ä–∞–π–ª–∞")
            unit = UNITS.get(measure, "")
            ax.set_ylabel(f"–ó–Ω–∞—á–µ–Ω–∏–µ, {unit}" if unit else "–ó–Ω–∞—á–µ–Ω–∏–µ")
            ax.set_xticks(trials)
            ax.grid(True, alpha=0.3)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–µ–Ω–¥—É —Ñ–∞–∑ (—Ç–æ–ª—å–∫–æ –Ω–∞ –ø–µ—Ä–≤–æ–º –≥—Ä–∞—Ñ–∏–∫–µ)
            if i == 0:
                legend_elements = []
                legend_labels = {
                    "baseline_2": "–ë–∞–∑–æ–≤–∞—è –ª–∏–Ω–∏—è (–¢2)",
                    "baseline_3": "–ë–∞–∑–æ–≤–∞—è –ª–∏–Ω–∏—è (–¢3)",
                    "stress_peak": "–ü–∏–∫ —Å—Ç—Ä–µ—Å—Å–∞ (–¢4)",
                    "stress_adapt": "–ê–¥–∞–ø—Ç–∞—Ü–∏—è (–¢5)",
                }
                for phase, color in phase_colors.items():
                    if phase in legend_labels:
                        legend_elements.append(
                            plt.Rectangle((0, 0), 1, 1, facecolor=color, alpha=0.8)
                        )
                
                ax.legend(
                    legend_elements,
                    list(legend_labels.values()),
                    loc="upper right",
                    fontsize=9,
                )
    
    # –û–±—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    fig.suptitle(
        "üìä –î–ò–ù–ê–ú–ò–ö–ê –°–¢–†–ï–°–°–ê –ë–ï–ó –ê–î–ê–ü–¢–ê–¶–ò–û–ù–ù–´–• –¢–†–ê–ô–õ–û–í (–¢2-–¢5)",
        fontsize=16,
        fontweight="bold",
        y=0.98,
    )
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.92)
    plt.savefig(
        f"{RESULTS_DIR}/clean_stress_dynamics.png", dpi=FIGURE_DPI, bbox_inches="tight"
    )
    show_plot_conditionally()
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è —á–∏—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –ë–ï–ó –ê–î–ê–ü–¢–ê–¶–ò–û–ù–ù–´–• –¢–†–ê–ô–õ–û–í:")
    print("=" * 50)
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ç—Ä–∞–π–ª—ã (2-3) —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–≤—ã–º–∏ (4-5)
    baseline_data = clean_data[clean_data['INDEX'].isin([2, 3])]
    stress_data = clean_data[clean_data['INDEX'].isin([4, 5])]
    
    print(f"   ‚Ä¢ –ë–∞–∑–æ–≤—ã–µ —Ç—Ä–∞–π–ª—ã (2-3): {len(baseline_data)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
    print(f"   ‚Ä¢ –°—Ç—Ä–µ—Å—Å–æ–≤—ã–µ —Ç—Ä–∞–π–ª—ã (4-5): {len(stress_data)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
    
    for measure in measures_for_clean_dynamics:
        baseline_values = baseline_data[measure].dropna()
        stress_values = stress_data[measure].dropna()
        
        if len(baseline_values) > 0 and len(stress_values) > 0:
            # t-—Ç–µ—Å—Ç
            from scipy.stats import ttest_ind
            t_stat, p_value = ttest_ind(baseline_values, stress_values)
            
            # Cohen's d
            pooled_std = np.sqrt(((len(baseline_values) - 1) * baseline_values.var() + 
                                 (len(stress_values) - 1) * stress_values.var()) / 
                                (len(baseline_values) + len(stress_values) - 2))
            cohens_d = (stress_values.mean() - baseline_values.mean()) / pooled_std
            
            # –ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
            change_pct = ((stress_values.mean() - baseline_values.mean()) / baseline_values.mean()) * 100
            
            print(f"\n   üìä {measure_names_map.get(measure, measure)}:")
            print(f"      –ë–∞–∑–æ–≤—ã–µ: {baseline_values.mean():.2f}¬±{baseline_values.std():.2f}")
            print(f"      –°—Ç—Ä–µ—Å—Å–æ–≤—ã–µ: {stress_values.mean():.2f}¬±{stress_values.std():.2f}")
            print(f"      –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {change_pct:+.1f}% | d = {cohens_d:.3f} | p = {p_value:.4f}")


def create_person_visualizations(data, comparison_results, trial_stats):
    """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ª—é–¥–µ–π"""
    print("\nüé® –°–û–ó–î–ê–ù–ò–ï –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ô...")
    
    # 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —É—Å–ª–æ–≤–∏–π (boxplot)
    fig, axes = plt.subplots(4, 5, figsize=(20, 16))
    axes = axes.flatten()
    
    key_measures = [
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–∫—Å–∞—Ü–∏–π
        'AVERAGE_FIXATION_DURATION', 'MEDIAN_FIXATION_DURATION', 'FIXATION_DURATION_MAX',
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∞–∫–∫–∞–¥
        'AVERAGE_SACCADE_AMPLITUDE', 'MEDIAN_SACCADE_AMPLITUDE',
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ—Ä–≥–∞–Ω–∏–π
        'AVERAGE_BLINK_DURATION',
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑—Ä–∞—á–∫–∞
        'PUPIL_SIZE_MEAN', 'PUPIL_SIZE_MAX',
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–Ω–∞ —Å–ª–æ–≤–æ)
        'DURATION_PER_WORD', 'FIXATIONS_PER_WORD', 'SACCADES_PER_WORD',
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–≤ —Å–µ–∫—É–Ω–¥—É)
        'FIXATIONS_PER_SECOND', 'SACCADES_PER_SECOND',
        
        # –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–∫—Å—Ç–∞
        'TEXT_COVERAGE_PERCENT', 'REVISITED_WORDS_PERCENT',
        
        # –í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã
        'REGRESSIVE_SACCADES', 'REGRESSIVE_SACCADES_PERCENT'
    ]
    
    for i, measure in enumerate(key_measures):
        if i >= len(axes):
            break
            
        ax = axes[i]
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        no_stress_data = data[data['condition'] == 'no_stress'][measure].dropna()
        stress_data = data[data['condition'] == 'stress'][measure].dropna()
        
        if len(no_stress_data) > 0 and len(stress_data) > 0:
            # –°–æ–∑–¥–∞–µ–º boxplot
            bp = ax.boxplot([no_stress_data, stress_data], 
                          labels=['–ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞', '–°–æ —Å—Ç—Ä–µ—Å—Å–æ–º'],
                          patch_artist=True)
            
            # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º
            bp['boxes'][0].set_facecolor(COLORS_NO_STRESS)
            bp['boxes'][1].set_facecolor(COLORS_STRESS)
            
            ax.set_title(f"{measure}")
            if measure in UNITS:
                ax.set_ylabel(f"–ó–Ω–∞—á–µ–Ω–∏–µ ({UNITS[measure]})")
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            result = next((r for r in comparison_results if r['measure'] == measure), None)
            if result:
                p_text = f"p = {result['p_value']:.3f}"
                d_text = f"d = {result['cohens_d']:.2f}"
                ax.text(0.02, 0.98, f"{p_text}\n{d_text}", 
                       transform=ax.transAxes, verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –æ—Å–∏
    for i in range(len(key_measures), len(axes)):
        fig.delaxes(axes[i])
    
    plt.tight_layout()
    plt.savefig(f"{RESULTS_DIR}/person_level_comparison.png", dpi=FIGURE_DPI, bbox_inches='tight')
    show_plot_conditionally()
    
    # 2. –£–ª—É—á—à–µ–Ω–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ —Ç—Ä–∞–π–ª–∞–º (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ comprehensive_eyetracking_analysis.py)
    create_enhanced_trial_dynamics_visualization(data, key_measures)
    
    # 3. –ì—Ä–∞—Ñ–∏–∫ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –¥–∏–Ω–∞–º–∏–∫–∏
    create_key_dynamics_visualization(data)
    
    # 4. –ì—Ä–∞—Ñ–∏–∫ —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –∞–¥–∞–ø—Ç–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç—Ä–∞–π–ª–æ–≤ (1 –∏ 6)
    create_clean_stress_dynamics_visualization(data)
    
    # 3. –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
    fig, axes = plt.subplots(5, 4, figsize=(20, 20))
    axes = axes.flatten()
    
    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
    participants = data['RECORDING_SESSION_LABEL'].unique()
    
    # –°–æ–∑–¥–∞–µ–º —Ü–≤–µ—Ç–æ–≤—É—é –ø–∞–ª–∏—Ç—Ä—É –¥–ª—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
    import matplotlib.cm as cm
    colors = cm.tab20(np.linspace(0, 1, len(participants)))
    
    for i, measure in enumerate(key_measures):
        if i >= len(axes):
            break
            
        ax = axes[i]
        
        for j, participant in enumerate(participants):
            participant_data = data[data['RECORDING_SESSION_LABEL'] == participant]
            participant_data = participant_data.sort_values('INDEX')
            
            if len(participant_data) > 0:
                trials = participant_data['INDEX'].values
                values = participant_data[measure].values
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ü–≤–µ—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞
                participant_color = colors[j]
                
                # –†–∏—Å—É–µ–º –ø–æ–ª–Ω—É—é —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é —É—á–∞—Å—Ç–Ω–∏–∫–∞
                ax.plot(trials, values, 'o-', 
                       color=participant_color, alpha=0.7, linewidth=1.5, markersize=4,
                       label=f'–£—á–∞—Å—Ç–Ω–∏–∫ {participant}')
        
        ax.set_title(f"{measure}")
        ax.set_xlabel("–ù–æ–º–µ—Ä —Ç—Ä–∞–π–ª–∞")
        if measure in UNITS:
            ax.set_ylabel(f"–ó–Ω–∞—á–µ–Ω–∏–µ ({UNITS[measure]})")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω—É—é –ª–∏–Ω–∏—é
        ax.axvline(x=STRESS_THRESHOLD + 0.5, color='black', linestyle='--', alpha=0.5)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ —É—Å–ª–æ–≤–∏–π
        ax.text(0.02, 0.98, f'–¢—Ä–∞–π–ª—ã 1-{STRESS_THRESHOLD}: –±–∞–∑–æ–≤—ã–µ\n–¢—Ä–∞–π–ª—ã {STRESS_THRESHOLD+1}-6: —Å—Ç—Ä–µ—Å—Å', 
                transform=ax.transAxes, fontsize=8, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –ª–µ–≥–µ–Ω–¥—É —Å–æ –≤—Å–µ–º–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏
        ax.legend(loc='upper right', fontsize=6, ncol=2, frameon=True, 
                 title='–£—á–∞—Å—Ç–Ω–∏–∫–∏', title_fontsize=7)
    
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –æ—Å–∏
    for i in range(len(key_measures), len(axes)):
        fig.delaxes(axes[i])
    
    plt.tight_layout()
    plt.savefig(f"{RESULTS_DIR}/person_individual_trajectories.png", dpi=FIGURE_DPI, bbox_inches='tight')
    show_plot_conditionally()


def test_formal_hypotheses(comparison_results):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–µ –Ω–∞—É—á–Ω—ã–µ –≥–∏–ø–æ—Ç–µ–∑—ã"""
    print("\nüî¨ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –§–û–†–ú–ê–õ–¨–ù–´–• –ì–ò–ü–û–¢–ï–ó...")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º p-–∑–Ω–∞—á–µ–Ω–∏—è
    p_values = [r['p_value'] for r in comparison_results]
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–ø—Ä–∞–≤–∫—É Bonferroni
    corrected_alpha, significant_count = apply_bonferroni_correction(p_values)
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    total_tests = len(comparison_results)
    significant_tests = sum(1 for r in comparison_results if r['p_value'] < ALPHA_LEVEL)
    significant_bonferroni = sum(1 for r in comparison_results if r['p_value'] < corrected_alpha)
    
    print(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}")
    print(f"   ‚Ä¢ –ó–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (p < {ALPHA_LEVEL}): {significant_tests}")
    print(f"   ‚Ä¢ –ó–Ω–∞—á–∏–º—ã—Ö –ø–æ—Å–ª–µ –ø–æ–ø—Ä–∞–≤–∫–∏ Bonferroni: {significant_bonferroni}")
    print(f"   ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {(significant_tests/total_tests)*100:.1f}%")
    
    # –§–æ—Ä–º—É–ª–∏—Ä—É–µ–º –≥–∏–ø–æ—Ç–µ–∑—ã
    print(f"\nüî∏ –ù–£–õ–ï–í–ê–Ø –ì–ò–ü–û–¢–ï–ó–ê (H0):")
    print(f"   –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞")
    print(f"   –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏ –±–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞ –∏ —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ª—é–¥–µ–π")
    
    print(f"\nüîπ –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–ê–Ø –ì–ò–ü–û–¢–ï–ó–ê (H1):")
    print(f"   –°—É—â–µ—Å—Ç–≤—É—é—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞")
    print(f"   –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏ –±–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞ –∏ —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ª—é–¥–µ–π")
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    if significant_bonferroni > 0:
        print(f"\n‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢: H0 –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø")
        print(f"   –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –ø–æ—Å–ª–µ –ø–æ–ø—Ä–∞–≤–∫–∏ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    else:
        print(f"\n‚ùå –†–ï–ó–£–õ–¨–¢–ê–¢: H0 –ù–ï –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø")
        print(f"   –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ä–∞–∑–ª–∏—á–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
    
    return {
        'total_tests': total_tests,
        'significant_tests': significant_tests,
        'significant_bonferroni': significant_bonferroni,
        'percent_significant': (significant_tests/total_tests)*100
    }


def generate_comprehensive_report(comparison_results, hypothesis_results):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç"""
    print("\nüìã –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –û–¢–ß–ï–¢–ê...")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É —ç—Ñ—Ñ–µ–∫—Ç–∞
    sorted_results = sorted(comparison_results, key=lambda x: abs(x['cohens_d']), reverse=True)
    
    print(f"\nüèÜ –¢–û–ü-10 –ü–û–ö–ê–ó–ê–¢–ï–õ–ï–ô –ü–û –†–ê–ó–ú–ï–†–£ –≠–§–§–ï–ö–¢–ê:")
    for i, result in enumerate(sorted_results[:10], 1):
        interpretation = interpret_effect_size_with_warnings(
            result['cohens_d'], result['p_value'], 
            result['n_no_stress'] + result['n_stress'], 
            result['measure']
        )
        print(f"   {i:2d}. {result['measure']}: {interpretation}")
        print(f"       –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {result['percent_change']:+.1f}% | p = {result['p_value']:.4f}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
    large_effects = sum(1 for r in comparison_results if abs(r['cohens_d']) >= EFFECT_SIZE_LARGE)
    medium_effects = sum(1 for r in comparison_results if EFFECT_SIZE_MEDIUM <= abs(r['cohens_d']) < EFFECT_SIZE_LARGE)
    small_effects = sum(1 for r in comparison_results if abs(r['cohens_d']) < EFFECT_SIZE_MEDIUM)
    
    print(f"\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –†–ê–ó–ú–ï–†–û–í –≠–§–§–ï–ö–¢–û–í:")
    print(f"   ‚Ä¢ –ë–æ–ª—å—à–∏–µ —ç—Ñ—Ñ–µ–∫—Ç—ã (|d| ‚â• {EFFECT_SIZE_LARGE}): {large_effects}")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç—ã ({EFFECT_SIZE_MEDIUM} ‚â§ |d| < {EFFECT_SIZE_LARGE}): {medium_effects}")
    print(f"   ‚Ä¢ –ú–∞–ª—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã (|d| < {EFFECT_SIZE_MEDIUM}): {small_effects}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if hypothesis_results['significant_bonferroni'] > 0:
        print(f"   ‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è")
        print(f"   ‚úÖ –ê–π—Ç—Ä–µ–∫–∏–Ω–≥ –º–æ–∂–µ—Ç –±—ã—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å—Ç—Ä–µ—Å—Å–∞")
    else:
        print(f"   ‚ö†Ô∏è  –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ä–∞–∑–ª–∏—á–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        print(f"   ‚ö†Ô∏è  –¢—Ä–µ–±—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –∏–ª–∏ —É–ª—É—á—à–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏")
    
    print(f"   üìà –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ñ–æ–∫—É—Å –Ω–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö —Å –±–æ–ª—å—à–∏–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤")
    print(f"   üî¨ –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π –≤—ã–±–æ—Ä–∫–µ")


def print_research_hypotheses():
    """–í—ã–≤–æ–¥–∏—Ç –Ω–∞—É—á–Ω—ã–µ –≥–∏–ø–æ—Ç–µ–∑—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
    print("\n" + "="*80)
    print("üî¨ –ù–ê–£–ß–ù–´–ï –ì–ò–ü–û–¢–ï–ó–´ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø")
    print("="*80)
    
    print("\nüî∏ –ù–£–õ–ï–í–ê–Ø –ì–ò–ü–û–¢–ï–ó–ê (H0):")
    print("   –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞")
    print("   –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏ –±–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞ –∏ —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ª—é–¥–µ–π")
    print("   –§–æ—Ä–º–∞–ª—å–Ω–æ: H0: Œº‚ÇÅ = Œº‚ÇÇ")
    
    print("\nüîπ –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–ê–Ø –ì–ò–ü–û–¢–ï–ó–ê (H1):")
    print("   –°—É—â–µ—Å—Ç–≤—É—é—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞")
    print("   –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏ –±–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞ –∏ —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ª—é–¥–µ–π")
    print("   –§–æ—Ä–º–∞–ª—å–Ω–æ: H1: Œº‚ÇÅ ‚â† Œº‚ÇÇ")
    
    print("\nüìä –ö–†–ò–¢–ï–†–ò–ò –ü–†–ò–ù–Ø–¢–ò–Ø –†–ï–®–ï–ù–ò–Ø:")
    print(f"   ‚Ä¢ –£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏: Œ± = {ALPHA_LEVEL}")
    print(f"   ‚Ä¢ –ö—Ä–∏—Ç–µ—Ä–∏–π –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è H0: p-value < {ALPHA_LEVEL}")
    print(f"   ‚Ä¢ –ö—Ä–∏—Ç–µ—Ä–∏–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏: |Cohen's d| ‚â• {EFFECT_SIZE_LARGE}")
    
    print("\nüéØ –û–ñ–ò–î–ê–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print("   –ü—Ä–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–∏ H1 –æ–∂–∏–¥–∞–µ—Ç—Å—è:")
    print("   ‚Ä¢ –£–º–µ–Ω—å—à–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ñ–∏–∫—Å–∞—Ü–∏–π (–ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)")
    print("   ‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–≤–∏–∂–µ–Ω–∏–π –≥–ª–∞–∑ (–ø–æ—Ç–µ—Ä—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏)")
    print("   ‚Ä¢ –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑—Ä–∞—á–∫–æ–≤ (–∞–∫—Ç–∏–≤–∞—Ü–∏—è —Å–∏–º–ø–∞—Ç–∏—á–µ—Å–∫–æ–π –Ω–µ—Ä–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã)")
    print("   ‚Ä¢ –ó–∞–º–µ–¥–ª–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á (–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –¥–µ—Ñ–∏—Ü–∏—Ç)")
    
    print("="*80)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    global DATA_FILE, RESULTS_DIR, SHOW_PLOTS, EXCLUDED_PARTICIPANTS
    
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    args = parse_arguments()
    DATA_FILE = args.data_file
    RESULTS_DIR = args.results_dir
    SHOW_PLOTS = args.show_plots
    EXCLUDED_PARTICIPANTS = args.exclude_participants
    
    print("üëÅÔ∏è  –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• –ê–ô–¢–†–ï–ö–ò–ù–ì–ê –ù–ê –£–†–û–í–ù–ï –õ–Æ–î–ï–ô")
    print("="*60)
    
    # –í—ã–≤–æ–¥–∏–º –≥–∏–ø–æ—Ç–µ–∑—ã
    print_research_hypotheses()
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    ensure_results_directory()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    data = load_person_data()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏
    comparison_results = analyze_person_level_differences(data)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∏–Ω–∞–º–∏–∫—É
    trial_stats = analyze_person_dynamics(data)
    
    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    create_person_visualizations(data, comparison_results, trial_stats)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–∏–ø–æ—Ç–µ–∑—ã
    hypothesis_results = test_formal_hypotheses(comparison_results)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    generate_comprehensive_report(comparison_results, hypothesis_results)
    
    print(f"\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {RESULTS_DIR}")
    print(f"üìä –°–æ–∑–¥–∞–Ω–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤: 3")
    print(f"üî¨ –ü—Ä–æ–≤–µ–¥–µ–Ω–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤: {len(comparison_results)}")


if __name__ == "__main__":
    main() 
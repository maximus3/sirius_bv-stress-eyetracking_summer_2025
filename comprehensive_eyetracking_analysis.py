import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_ind, mannwhitneyu, wilcoxon, shapiro, levene, kruskal, spearmanr
import os
import warnings
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –∫—Ä–∞—Å–∏–≤—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
plt.style.use('seaborn-v0_8')
plt.rcParams['font.family'] = ['DejaVu Sans']
plt.rcParams['font.size'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12

def ensure_results_directory():
    """–°–æ–∑–¥–∞–µ—Ç –ø–∞–ø–∫—É results –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
    if not os.path.exists('results'):
        os.makedirs('results')
        print("üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ 'results' –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤")
    else:
        print("üìÅ –ü–∞–ø–∫–∞ 'results' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

def load_comprehensive_data():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞ –∏–∑ –¥–≤—É—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
    1. ia_avg.xls - –¥–∞–Ω–Ω—ã–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤
    2. events.xls - –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç—Ä–∞–π–ª–æ–≤
    """
    print("üîÑ –ö–û–ú–ü–õ–ï–ö–°–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ê–ô–¢–†–ï–ö–ò–ù–ì–ê")
    print("=" * 70)
    
    # 1. –î–ê–ù–ù–´–ï –ù–ê –£–†–û–í–ù–ï –°–õ–û–í (ia_avg.xls)
    print("üìñ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤...")
    word_data = pd.read_csv('ia_avg.xls', sep='\t', encoding='utf-16', skiprows=1)
    col_names = list(word_data.columns)
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É –ø–æ —É—Å–ª–æ–≤–∏—è–º –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤
    trial_col = col_names[0]
    word_data['trial'] = word_data[trial_col].astype(int)
    word_data['condition'] = word_data['trial'].apply(lambda x: 'no_stress' if x <= 3 else 'stress')
    
    # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É –ø–æ —Ñ–∞–∑–∞–º –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤
    word_data['stress_phase'] = word_data['trial'].map({
        1: 'baseline_1', 2: 'baseline_2', 3: 'baseline_3',
        4: 'stress_peak', 5: 'stress_adapt', 6: 'stress_recovery'
    })
    
    # –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å–ª–æ–≤
    word_measure_names = {
        'IA_FIRST_FIXATION_DURATION': '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–≤–æ–π —Ñ–∏–∫—Å–∞—Ü–∏–∏ (–º—Å)',
        'IA_FIXATION_COUNT': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–∫—Å–∞—Ü–∏–π –Ω–∞ —Å–ª–æ–≤–æ',
        'IA_DWELL_TIME': '–û–±—â–µ–µ –≤—Ä–µ–º—è –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è (–º—Å)',
        'IA_DWELL_TIME_%': '–ü—Ä–æ—Ü–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è (%)',
        'IA_VISITED_TRIAL_%': '–ü—Ä–æ—Ü–µ–Ω—Ç –≤–∏–∑–∏—Ç–æ–≤ –∫ —Å–ª–æ–≤—É (%)',
        'IA_REVISIT_TRIAL_%': '–ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –≤–∏–∑–∏—Ç–æ–≤ (%)',
        'IA_RUN_COUNT': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–±–µ–≥–∞–Ω–∏–π –≤–∑–≥–ª—è–¥–∞'
    }
    
    # –ù–∞—Ö–æ–¥–∏–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å–ª–æ–≤
    numeric_cols_positions = [3, 4, 7, 8, 9, 10, 11]
    word_numeric_cols = [col_names[i] for i in numeric_cols_positions if i < len(col_names)]
    word_short_names = [
        'IA_FIRST_FIXATION_DURATION', 'IA_FIXATION_COUNT', 'IA_DWELL_TIME_%', 
        'IA_DWELL_TIME', 'IA_VISITED_TRIAL_%', 'IA_REVISIT_TRIAL_%', 'IA_RUN_COUNT'
    ]
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤
    for col in word_numeric_cols:
        if col in word_data.columns:
            word_data[col] = pd.to_numeric(word_data[col].astype(str).str.replace(',', '.'), errors='coerce')
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è —Å–ª–æ–≤
    for i, col in enumerate(word_numeric_cols):
        if col in word_data.columns and i < len(word_short_names):
            word_data[word_short_names[i]] = word_data[col]
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤
    word_col = col_names[6]
    word_data = word_data.dropna(subset=[word_col])
    word_data = word_data[word_data[word_col] != '.']
    word_data = word_data[word_data[word_col] != '‚Äì']
    word_data = word_data[word_data[word_col] != '‚Äî']
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(word_data)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤")
    
    # 2. –î–ê–ù–ù–´–ï –ù–ê –£–†–û–í–ù–ï –¢–†–ê–ô–õ–û–í (events.xls)
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç—Ä–∞–π–ª–æ–≤...")
    trial_data = pd.read_csv('events.xls', sep='\t', encoding='utf-16', header=0)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –∏ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ
    trial_data = trial_data.iloc[1:].reset_index(drop=True)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–∞–ø—è—Ç—ã–µ –≤ —Ç–æ—á–∫–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–∞
    for col in trial_data.columns:
        trial_data[col] = pd.to_numeric(trial_data[col].astype(str).str.replace(',', '.'), errors='coerce')
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç—Ä–∞–π–ª–∞—Ö
    trial_data['trial'] = range(1, len(trial_data) + 1)
    trial_data['condition'] = trial_data['trial'].apply(lambda x: 'no_stress' if x <= 3 else 'stress')
    trial_data['phase'] = trial_data['trial'].map({
        1: 'baseline_1', 2: 'baseline_2', 3: 'baseline_3',
        4: 'stress_peak', 5: 'stress_adapt', 6: 'stress_recovery'
    })
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    trial_data.columns = [
        'blinks', 'fixations', 'fixation_duration_mean', 'fixation_duration_median',
        'fixation_duration_sd', 'pupil_size', 'runs', 'saccade_amplitude_mean',
        'saccade_amplitude_median', 'saccade_amplitude_sd', 'saccades',
        'samples', 'trial_duration', 'interest_areas', 'visited_areas',
        'trial', 'condition', 'phase'
    ]
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(trial_data)} —Ç—Ä–∞–π–ª–æ–≤")
    print(f"   ‚Ä¢ –ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞ (—Ç—Ä–∞–π–ª—ã 1-3): {len(trial_data[trial_data['condition'] == 'no_stress'])} —Ç—Ä–∞–π–ª–∞")
    print(f"   ‚Ä¢ –°–æ —Å—Ç—Ä–µ—Å—Å–æ–º (—Ç—Ä–∞–π–ª—ã 4-6): {len(trial_data[trial_data['condition'] == 'stress'])} —Ç—Ä–∞–π–ª–∞")
    
    return word_data, trial_data, word_measure_names

def analyze_word_level_differences(word_data, word_measure_names):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏ –±–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞ –∏ —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º
    """
    print(f"\nüìù –ê–ù–ê–õ–ò–ó –†–ê–ó–õ–ò–ß–ò–ô –ù–ê –£–†–û–í–ù–ï –°–õ–û–í")
    print("=" * 70)
    
    measures = ['IA_FIRST_FIXATION_DURATION', 'IA_FIXATION_COUNT', 'IA_DWELL_TIME',
                'IA_DWELL_TIME_%', 'IA_VISITED_TRIAL_%', 'IA_REVISIT_TRIAL_%', 'IA_RUN_COUNT']
    
    results = []
    
    # –î–∞–Ω–Ω—ã–µ –ø–æ —É—Å–ª–æ–≤–∏—è–º
    no_stress = word_data[word_data['condition'] == 'no_stress']
    stress = word_data[word_data['condition'] == 'stress']
    
    print(f"üìä –°–†–ê–í–ù–ï–ù–ò–ï –ì–†–£–ü–ü –ù–ê –£–†–û–í–ù–ï –°–õ–û–í:")
    print(f"   –ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞: {len(no_stress)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")  
    print(f"   –°–æ —Å—Ç—Ä–µ—Å—Å–æ–º: {len(stress)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
    
    for measure in measures:
        if measure not in word_data.columns:
            continue
            
        print(f"\nüìà {word_measure_names.get(measure, measure)}")
        print("-" * 50)
        
        no_stress_vals = no_stress[measure].dropna()
        stress_vals = stress[measure].dropna()
        
        if len(no_stress_vals) == 0 or len(stress_vals) == 0:
            continue
        
        # –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        ns_mean, ns_std = no_stress_vals.mean(), no_stress_vals.std()
        s_mean, s_std = stress_vals.mean(), stress_vals.std()
        
        print(f"–ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞: M = {ns_mean:.2f} ¬± {ns_std:.2f}")
        print(f"–°–æ —Å—Ç—Ä–µ—Å—Å–æ–º:  M = {s_mean:.2f} ¬± {s_std:.2f}")
        
        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ
        change = s_mean - ns_mean
        change_pct = (change / ns_mean) * 100 if ns_mean != 0 else 0
        change_symbol = "üìà" if change > 0 else "üìâ"
        change_direction = "—É–≤–µ–ª–∏—á–µ–Ω–∏–µ" if change > 0 else "—É–º–µ–Ω—å—à–µ–Ω–∏–µ"
        print(f"{change_symbol} –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {change:+.2f} ({change_pct:+.1f}%)")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç (–ø—Ä–æ–≤–µ—Ä–∫–∞ H0: Œº‚ÇÅ = Œº‚ÇÇ –ø—Ä–æ—Ç–∏–≤ H1: Œº‚ÇÅ ‚â† Œº‚ÇÇ)
        try:
            stat, p_value = mannwhitneyu(no_stress_vals, stress_vals, alternative='two-sided')
            test_name = "–ö—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏"
        except:
            try:
                stat, p_value = ttest_ind(no_stress_vals, stress_vals)
                test_name = "t-–∫—Ä–∏—Ç–µ—Ä–∏–π"
            except:
                p_value = np.nan
                test_name = "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"
                
        if not np.isnan(p_value):
            if p_value < 0.05:
                significance = "‚úÖ H0 –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø (p < 0.05)"
                hypothesis_result = "–†–∞–∑–ª–∏—á–∏—è –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò –ó–ù–ê–ß–ò–ú–´"
            else:
                significance = "üî∏ H0 –ù–ï –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø (p ‚â• 0.05)"  
                hypothesis_result = "–†–∞–∑–ª–∏—á–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –ù–ï –ó–ù–ê–ß–ò–ú–´"
            print(f"üß™ {test_name}: p = {p_value:.4f} - {significance}")
            print(f"‚öñÔ∏è –ó–∞–∫–ª—é—á–µ–Ω–∏–µ: {hypothesis_result}")
        else:
            print(f"üß™ {test_name}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–∏–ø–æ—Ç–µ–∑")
        
        # –†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞ (Cohen's d)
        pooled_std = np.sqrt(((len(no_stress_vals) - 1) * ns_std**2 + 
                            (len(stress_vals) - 1) * s_std**2) / 
                           (len(no_stress_vals) + len(stress_vals) - 2))
        cohens_d = (s_mean - ns_mean) / pooled_std if pooled_std > 0 else 0
        
        effect_size = "–±–æ–ª—å—à–æ–π" if abs(cohens_d) >= 0.8 else "—Å—Ä–µ–¥–Ω–∏–π" if abs(cohens_d) >= 0.5 else "–º–∞–ª—ã–π"
        print(f"üìè –†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞: {effect_size} (d = {cohens_d:.3f})")
        
        results.append({
            'measure': measure,
            'measure_name': word_measure_names.get(measure, measure),
            'mean_no_stress': ns_mean,
            'std_no_stress': ns_std,
            'mean_stress': s_mean,
            'std_stress': s_std,
            'change_absolute': change,
            'change_percent': change_pct,
            'change_direction': change_direction,
            'p_value': p_value,
            'cohens_d': cohens_d,
            'significant': p_value < 0.05 if not np.isnan(p_value) else False
        })
    
    return results

def analyze_trial_level_differences(trial_data):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç—Ä–∞–π–ª–æ–≤ –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏ –±–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞ –∏ —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º
    """
    print(f"\nüßÆ –ê–ù–ê–õ–ò–ó –†–ê–ó–õ–ò–ß–ò–ô –ù–ê –£–†–û–í–ù–ï –¢–†–ê–ô–õ–û–í")
    print("=" * 70)
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    measures = [
        'blinks', 'fixations', 'fixation_duration_mean', 'fixation_duration_median',
        'pupil_size', 'runs', 'saccade_amplitude_mean', 'saccades', 
        'trial_duration', 'visited_areas'
    ]
    
    # –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    measure_names = {
        'blinks': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ—Ä–≥–∞–Ω–∏–π',
        'fixations': '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–∫—Å–∞—Ü–∏–π', 
        'fixation_duration_mean': '–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–∫—Å–∞—Ü–∏–π (–º—Å)',
        'fixation_duration_median': '–ú–µ–¥–∏–∞–Ω–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–∫—Å–∞—Ü–∏–π (–º—Å)',
        'pupil_size': '–†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞ (—Å—Ä–µ–¥–Ω–∏–π)',
        'runs': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–±–µ–≥–∞–Ω–∏–π –≤–∑–≥–ª—è–¥–∞',
        'saccade_amplitude_mean': '–°—Ä–µ–¥–Ω—è—è –∞–º–ø–ª–∏—Ç—É–¥–∞ —Å–∞–∫–∫–∞–¥ (¬∞)',
        'saccades': '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–∫–∫–∞–¥',
        'trial_duration': '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç—Ä–∞–π–ª–∞ (–º—Å)',
        'visited_areas': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–µ—â–µ–Ω–Ω—ã—Ö –∑–æ–Ω'
    }
    
    results = []
    
    # –î–∞–Ω–Ω—ã–µ –ø–æ —É—Å–ª–æ–≤–∏—è–º
    no_stress = trial_data[trial_data['condition'] == 'no_stress']
    stress = trial_data[trial_data['condition'] == 'stress']
    
    print(f"üìä –°–†–ê–í–ù–ï–ù–ò–ï –ì–†–£–ü–ü:")
    print(f"   –ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞: {len(no_stress)} —Ç—Ä–∞–π–ª–∞")  
    print(f"   –°–æ —Å—Ç—Ä–µ—Å—Å–æ–º: {len(stress)} —Ç—Ä–∞–π–ª–∞")
    
    for measure in measures:
        if measure not in trial_data.columns:
            continue
            
        print(f"\nüìà {measure_names.get(measure, measure)}")
        print("-" * 50)
        
        no_stress_vals = no_stress[measure].dropna()
        stress_vals = stress[measure].dropna()
        
        # –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        ns_mean, ns_std = no_stress_vals.mean(), no_stress_vals.std()
        s_mean, s_std = stress_vals.mean(), stress_vals.std()
        
        print(f"–ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞: M = {ns_mean:.2f} ¬± {ns_std:.2f}")
        print(f"–°–æ —Å—Ç—Ä–µ—Å—Å–æ–º:  M = {s_mean:.2f} ¬± {s_std:.2f}")
        
        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ
        change = s_mean - ns_mean
        change_pct = (change / ns_mean) * 100 if ns_mean != 0 else 0
        change_symbol = "üìà" if change > 0 else "üìâ"
        print(f"{change_symbol} –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {change:+.2f} ({change_pct:+.1f}%)")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç (–ø—Ä–æ–≤–µ—Ä–∫–∞ H0: Œº‚ÇÅ = Œº‚ÇÇ –ø—Ä–æ—Ç–∏–≤ H1: Œº‚ÇÅ ‚â† Œº‚ÇÇ)
        # –° —Ç–∞–∫–æ–π –º–∞–ª–µ–Ω—å–∫–æ–π –≤—ã–±–æ—Ä–∫–æ–π (3 vs 3) –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—ã–µ —Ç–µ—Å—Ç—ã
        if len(no_stress_vals) >= 3 and len(stress_vals) >= 3:
            # Wilcoxon rank-sum test (–∞–Ω–∞–ª–æ–≥ Mann-Whitney –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –≤—ã–±–æ—Ä–æ–∫)
            try:
                stat, p_value = mannwhitneyu(no_stress_vals, stress_vals, alternative='two-sided')
                test_name = "–ö—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏"
            except:
                # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º t-test
                stat, p_value = ttest_ind(no_stress_vals, stress_vals)
                test_name = "t-–∫—Ä–∏—Ç–µ—Ä–∏–π"
            
            if p_value < 0.05:
                significance = "‚úÖ H0 –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø (p < 0.05)"
                hypothesis_result = "–†–∞–∑–ª–∏—á–∏—è –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò –ó–ù–ê–ß–ò–ú–´"
            else:
                significance = "üî∏ H0 –ù–ï –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø (p ‚â• 0.05)"
                hypothesis_result = "–†–∞–∑–ª–∏—á–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –ù–ï –ó–ù–ê–ß–ò–ú–´"
                
            print(f"üß™ {test_name}: p = {p_value:.4f} - {significance}")
            print(f"‚öñÔ∏è –ó–∞–∫–ª—é—á–µ–Ω–∏–µ: {hypothesis_result}")
            
            if p_value >= 0.05:
                print(f"üí° –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ú–∞–ª—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ (N = 6) –º–æ–∂–µ—Ç –≤–ª–∏—è—Ç—å –Ω–∞ –º–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞")
            
            # –†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞ (Cohen's d)
            pooled_std = np.sqrt(((len(no_stress_vals) - 1) * ns_std**2 + 
                                (len(stress_vals) - 1) * s_std**2) / 
                               (len(no_stress_vals) + len(stress_vals) - 2))
            cohens_d = (s_mean - ns_mean) / pooled_std if pooled_std > 0 else 0
            
            effect_size = "–±–æ–ª—å—à–æ–π" if abs(cohens_d) >= 0.8 else "—Å—Ä–µ–¥–Ω–∏–π" if abs(cohens_d) >= 0.5 else "–º–∞–ª—ã–π"
            print(f"üìè –†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞: {effect_size} (d = {cohens_d:.3f})")
            
        else:
            p_value = np.nan
            test_name = "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"
            cohens_d = 0
            
        results.append({
            'measure': measure,
            'measure_name': measure_names.get(measure, measure),
            'no_stress_mean': ns_mean,
            'no_stress_std': ns_std,
            'stress_mean': s_mean,
            'stress_std': s_std,
            'change_absolute': change,
            'change_percent': change_pct,
            'p_value': p_value,
            'cohens_d': cohens_d,
            'significant': p_value < 0.05 if not np.isnan(p_value) else False
        })
    
    return results

def analyze_trial_dynamics(trial_data):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∏–Ω–∞–º–∏–∫—É –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Ç—Ä–∞–π–ª–∞–º
    """
    print(f"\nüìà –ê–ù–ê–õ–ò–ó –î–ò–ù–ê–ú–ò–ö–ò –ü–û –¢–†–ê–ô–õ–ê–ú")
    print("=" * 70)
    
    measures = [
        'blinks', 'fixations', 'fixation_duration_mean', 'pupil_size', 
        'runs', 'saccade_amplitude_mean', 'saccades', 'visited_areas'
    ]
    
    measure_names = {
        'blinks': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ—Ä–≥–∞–Ω–∏–π',
        'fixations': '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–∫—Å–∞—Ü–∏–π', 
        'fixation_duration_mean': '–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–∫—Å–∞—Ü–∏–π (–º—Å)',
        'pupil_size': '–†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞',
        'runs': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–±–µ–≥–∞–Ω–∏–π',
        'saccade_amplitude_mean': '–ê–º–ø–ª–∏—Ç—É–¥–∞ —Å–∞–∫–∫–∞–¥ (¬∞)',
        'saccades': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–∫–∫–∞–¥',
        'visited_areas': '–ü–æ—Å–µ—â–µ–Ω–Ω—ã–µ –∑–æ–Ω—ã'
    }
    
    dynamics = {}
    trial_stats = {}
    
    for measure in measures:
        if measure not in trial_data.columns:
            continue
            
        print(f"\nüìä {measure_names.get(measure, measure)}")
        print("-" * 40)
        
        # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —Ç—Ä–∞–π–ª–∞–º
        values = []
        phases = []
        trial_stats[measure] = {}
        
        for trial in range(1, 7):
            val = trial_data[trial_data['trial'] == trial][measure].iloc[0]
            phase = trial_data[trial_data['trial'] == trial]['phase'].iloc[0]
            values.append(val)
            phases.append(phase)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç—Ä–∞–π–ª–∞
            trial_stats[measure][trial] = {
                'mean': val,
                'std': 0,  # –£ –Ω–∞—Å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–∞–π–ª
                'phase': phase
            }
            
            phase_emoji = {"baseline_1": "üìä", "baseline_2": "üìä", "baseline_3": "üìä",
                          "stress_peak": "üî•", "stress_adapt": "üìâ", "stress_recovery": "üòå"}
            
            print(f"   {phase_emoji.get(phase, 'üìä')} –¢—Ä–∞–π–ª {trial}: {val:.2f}")
        
        # –ë–∞–∑–æ–≤–∞—è –ª–∏–Ω–∏—è
        baseline = np.mean(values[:3])
        
        # –ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–∞–∑–æ–≤–æ–π –ª–∏–Ω–∏–∏
        changes = [(v - baseline) / baseline * 100 for v in values]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω
        peak_trial = np.argmax(np.abs(changes)) + 1
        if peak_trial == 4:  # –ü–∏–∫ –≤ —Ç—Ä–∞–π–ª–µ 4
            if abs(changes[5]) < abs(changes[3]):  # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∫ —Ç—Ä–∞–π–ª—É 6
                pattern = "üéØ –ü–ò–ö –≤ –¢4 ‚Üí –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï"
            else:
                pattern = "üî• –ü–ò–ö –≤ –¢4 ‚Üí –ë–ï–ó –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–Ø"
        else:
            pattern = "‚ùì –ù–ï–°–¢–ê–ù–î–ê–†–¢–ù–´–ô –ü–ê–¢–¢–ï–†–ù"
            
        print(f"   üéØ –ü–∞—Ç—Ç–µ—Ä–Ω: {pattern}")
        print(f"   üìä –ë–∞–∑–æ–≤–∞—è –ª–∏–Ω–∏—è: {baseline:.2f}")
        print(f"   üìà –ú–∞–∫—Å. –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {max(changes, key=abs):.1f}% (–¢—Ä–∞–π–ª {peak_trial})")
        
        dynamics[measure] = {
            'values': values,
            'phases': phases,
            'changes': changes,
            'baseline': baseline,
            'pattern': pattern
        }
    
    return dynamics, trial_stats

def analyze_word_dynamics(word_data, word_measure_names):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∏–Ω–∞–º–∏–∫—É –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤ –ø–æ —Ç—Ä–∞–π–ª–∞–º
    """
    print(f"\nüìù –ê–ù–ê–õ–ò–ó –î–ò–ù–ê–ú–ò–ö–ò –°–õ–û–í –ü–û –¢–†–ê–ô–õ–ê–ú")
    print("=" * 70)
    
    measures = ['IA_FIRST_FIXATION_DURATION', 'IA_FIXATION_COUNT', 'IA_DWELL_TIME',
                'IA_DWELL_TIME_%', 'IA_VISITED_TRIAL_%', 'IA_REVISIT_TRIAL_%', 'IA_RUN_COUNT']
    
    word_trial_stats = {}
    word_dynamics_results = {}
    
    for measure in measures:
        if measure not in word_data.columns:
            continue
            
        print(f"\nüìä {word_measure_names.get(measure, measure)}")
        print("-" * 50)
        
        word_trial_stats[measure] = {}
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞–∂–¥–æ–º—É —Ç—Ä–∞–π–ª—É
        trial_values = []
        for trial in range(1, 7):
            trial_data = word_data[word_data['trial'] == trial][measure].dropna()
            if len(trial_data) > 0:
                mean_val = trial_data.mean()
                std_val = trial_data.std()
                phase = word_data[word_data['trial'] == trial]['stress_phase'].iloc[0]
            else:
                mean_val = 0
                std_val = 0
                phase = f'trial_{trial}'
            
            word_trial_stats[measure][trial] = {
                'mean': mean_val,
                'std': std_val,
                'phase': phase,
                'count': len(trial_data)
            }
            trial_values.append(mean_val)
            
            print(f"   –¢—Ä–∞–π–ª {trial}: M = {mean_val:.2f} ¬± {std_val:.2f} (n = {len(trial_data)})")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
        baseline_vs_peak_p = np.nan
        peak_vs_recovery_p = np.nan
        
        try:
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –ª–∏–Ω–∏–∏ (1-3) —Å –ø–∏–∫–æ–º —Å—Ç—Ä–µ—Å—Å–∞ (4)
            baseline_data = []
            for t in [1, 2, 3]:
                baseline_data.extend(word_data[word_data['trial'] == t][measure].dropna().tolist())
            peak_data = word_data[word_data['trial'] == 4][measure].dropna().tolist()
            
            if len(baseline_data) > 0 and len(peak_data) > 0:
                _, baseline_vs_peak_p = mannwhitneyu(baseline_data, peak_data, alternative='two-sided')
            
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–∏–∫–∞ —Å—Ç—Ä–µ—Å—Å–∞ (4) —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º (6)
            recovery_data = word_data[word_data['trial'] == 6][measure].dropna().tolist()
            if len(peak_data) > 0 and len(recovery_data) > 0:
                _, peak_vs_recovery_p = mannwhitneyu(peak_data, recovery_data, alternative='two-sided')
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–º —Ç–µ—Å—Ç–µ: {e}")
        
        word_dynamics_results[measure] = {
            'baseline_vs_peak_p': baseline_vs_peak_p,
            'peak_vs_recovery_p': peak_vs_recovery_p,
            'measure': measure
        }
        
        if not np.isnan(baseline_vs_peak_p):
            print(f"   üß™ –ë–∞–∑–∞ vs –ü–∏–∫: p = {baseline_vs_peak_p:.4f}")
        if not np.isnan(peak_vs_recovery_p):
            print(f"   üß™ –ü–∏–∫ vs –í–æ—Å—Å—Ç.: p = {peak_vs_recovery_p:.4f}")
    
    return word_trial_stats, word_dynamics_results

def create_enhanced_word_visualizations(word_data, word_test_results, word_measure_names):
    """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤"""
    print(f"\nüé® –°–û–ó–î–ê–ù–ò–ï –ì–†–ê–§–ò–ö–û–í –ê–ù–ê–õ–ò–ó–ê –°–õ–û–í")
    print("=" * 50)
    
    measures = [r['measure'] for r in word_test_results]
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É
    fig, axes = plt.subplots(3, 3, figsize=(20, 16))
    axes = axes.flatten()
    
    colors_no_stress = '#2E86C1'  # –°–∏–Ω–∏–π
    colors_stress = '#E74C3C'     # –ö—Ä–∞—Å–Ω—ã–π
    
    for i, result in enumerate(word_test_results):
        if i >= len(axes):
            break
            
        ax = axes[i]
        measure = result['measure']
        
        # –î–∞–Ω–Ω—ã–µ –¥–ª—è boxplot
        no_stress_data = word_data[word_data['condition'] == 'no_stress'][measure].dropna()
        stress_data = word_data[word_data['condition'] == 'stress'][measure].dropna()
        
        if len(no_stress_data) == 0 or len(stress_data) == 0:
            ax.text(0.5, 0.5, '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ\n–¥–∞–Ω–Ω—ã—Ö', ha='center', va='center', transform=ax.transAxes)
            ax.set_title(f"{result['measure_name']}", fontweight='bold', fontsize=11)
            continue
        
        # –°–æ–∑–¥–∞–µ–º boxplot
        bp = ax.boxplot([no_stress_data, stress_data], 
                       labels=['–ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞', '–°–æ —Å—Ç—Ä–µ—Å—Å–æ–º'],
                       patch_artist=True,
                       notch=True,
                       widths=0.6)
        
        # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º –±–æ–∫—Å—ã
        bp['boxes'][0].set_facecolor(colors_no_stress)
        bp['boxes'][0].set_alpha(0.7)
        bp['boxes'][1].set_facecolor(colors_stress)
        bp['boxes'][1].set_alpha(0.7)
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è
        ax.set_title(f"{result['measure_name']}", fontweight='bold', fontsize=11)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–µ–ª–∫—É –ø–æ–∫–∞–∑—ã–≤–∞—é—â—É—é –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        y_max = max(no_stress_data.max(), stress_data.max())
        y_min = min(no_stress_data.min(), stress_data.min())
        y_range = y_max - y_min
        
        # –ü–æ–∑–∏—Ü–∏—è –¥–ª—è —Å—Ç—Ä–µ–ª–∫–∏ –∏ —Ç–µ–∫—Å—Ç–∞
        arrow_y = y_max + y_range * 0.1
        text_y = y_max + y_range * 0.15
        
        if result['change_direction'] == '—É–≤–µ–ª–∏—á–µ–Ω–∏–µ':
            ax.annotate('', xy=(2, arrow_y), xytext=(1, arrow_y),
                       arrowprops=dict(arrowstyle='->', lw=2, color='red'))
            direction_symbol = "‚ÜóÔ∏è"
        else:
            ax.annotate('', xy=(1, arrow_y), xytext=(2, arrow_y),
                       arrowprops=dict(arrowstyle='->', lw=2, color='blue'))
            direction_symbol = "‚ÜòÔ∏è"
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏–∏
        change_text = f"{direction_symbol} {abs(result['change_percent']):.1f}%"
        ax.text(1.5, text_y, change_text, ha='center', va='bottom', 
                fontweight='bold', fontsize=10)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
        if result['significant']:
            significance_text = f"p = {result['p_value']:.3f} ‚úÖ"
            bbox_color = 'lightgreen'
        else:
            significance_text = f"p = {result['p_value']:.3f} ‚ùå"
            bbox_color = 'lightcoral'
        
        ax.text(0.5, 0.02, significance_text, transform=ax.transAxes, 
                ha='center', va='bottom',
                bbox=dict(boxstyle="round,pad=0.3", facecolor=bbox_color, alpha=0.7))
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞–∫ —Ç–æ—á–∫–∏
        ax.scatter([1], [result['mean_no_stress']], color='darkblue', s=50, zorder=10, marker='D')
        ax.scatter([2], [result['mean_stress']], color='darkred', s=50, zorder=10, marker='D')
        
        ax.grid(True, alpha=0.3)
        ax.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')
    
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∏
    for i in range(len(word_test_results), len(axes)):
        fig.delaxes(axes[i])
    
    # –û–±—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    fig.suptitle('üìù –í–õ–ò–Ø–ù–ò–ï –°–¢–†–ï–°–°–ê –ù–ê –ü–ê–†–ê–ú–ï–¢–†–´ –ê–ô–¢–†–ï–ö–ò–ù–ì–ê –ü–†–ò –ß–¢–ï–ù–ò–ò (–£–†–û–í–ï–ù–¨ –°–õ–û–í)', 
                 fontsize=16, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.93)
    plt.savefig('results/word_level_stress_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def create_dynamics_visualizations(trial_data, trial_stats, word_data, word_trial_stats, 
                                 word_dynamics_results, word_measure_names):
    """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –¥–∏–Ω–∞–º–∏–∫–∏ —Å—Ç—Ä–µ—Å—Å–∞ –ø–æ —Ç—Ä–∞–π–ª–∞–º –¥–ª—è –æ–±–æ–∏—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
    print(f"\nüé® –°–û–ó–î–ê–ù–ò–ï –ì–†–ê–§–ò–ö–û–í –î–ò–ù–ê–ú–ò–ö–ò –ü–û –¢–†–ê–ô–õ–ê–ú")
    print("=" * 50)
    
    # 1. –î–ò–ù–ê–ú–ò–ö–ê –ù–ê –£–†–û–í–ù–ï –¢–†–ê–ô–õ–û–í
    print("üìä –ì—Ä–∞—Ñ–∏–∫–∏ –¥–∏–Ω–∞–º–∏–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç—Ä–∞–π–ª–æ–≤...")
    
    trial_measures = list(trial_stats.keys())
    
    # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à—É—é —Ñ–∏–≥—É—Ä—É –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–∞–π–ª–æ–≤
    fig1, axes1 = plt.subplots(3, 3, figsize=(24, 18))
    axes1 = axes1.flatten()
    
    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ñ–∞–∑
    phase_colors = {
        'baseline_1': '#3498DB',   # –°–∏–Ω–∏–π
        'baseline_2': '#5DADE2',   # –°–≤–µ—Ç–ª–æ-—Å–∏–Ω–∏–π  
        'baseline_3': '#85C1E9',   # –ï—â–µ —Å–≤–µ—Ç–ª–µ–µ —Å–∏–Ω–∏–π
        'stress_peak': '#E74C3C',  # –ö—Ä–∞—Å–Ω—ã–π (–ø–∏–∫)
        'stress_adapt': '#F1948A', # –†–æ–∑–æ–≤—ã–π (–∞–¥–∞–ø—Ç–∞—Ü–∏—è)
        'stress_recovery': '#F8C471' # –ñ–µ–ª—Ç—ã–π (–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ)
    }
    
    for i, measure in enumerate(trial_measures):
        if i >= len(axes1):
            break
        
        ax = axes1[i]
        
        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
        trials = sorted(trial_stats[measure].keys())
        means = [trial_stats[measure][t]['mean'] for t in trials]
        stds = [trial_stats[measure][t]['std'] for t in trials]
        phases = [trial_stats[measure][t]['phase'] for t in trials]
        colors = [phase_colors[phase] for phase in phases]
        
        # –°–æ–∑–¥–∞–µ–º bar plot —Å —Ä–∞–∑–Ω—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏ –¥–ª—è —Ñ–∞–∑
        bars = ax.bar(trials, means, yerr=stds, capsize=5, 
                     color=colors, alpha=0.8, edgecolor='black', linewidth=1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é —Ç—Ä–µ–Ω–¥–∞
        ax.plot(trials, means, 'k--', alpha=0.7, linewidth=2, marker='o', markersize=6)
        
        # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è —Ä–∞–∑–¥–µ–ª—è—é—â–∞—è —Ñ–∞–∑—ã
        ax.axvline(x=3.5, color='red', linestyle=':', linewidth=2, alpha=0.7)
        ax.text(3.5, max(means) * 0.9, '–ù–ê–ß–ê–õ–û\n–°–¢–†–ï–°–°–ê', ha='center', va='center', 
               bbox=dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.3))
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        trial_measure_names = {
            'blinks': '–ú–æ—Ä–≥–∞–Ω–∏—è', 'fixations': '–§–∏–∫—Å–∞—Ü–∏–∏', 
            'fixation_duration_mean': '–î–ª–∏—Ç. —Ñ–∏–∫—Å–∞—Ü–∏–π', 'pupil_size': '–†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞',
            'runs': '–ó–∞–±–µ–≥–∞–Ω–∏—è', 'saccade_amplitude_mean': '–ê–º–ø–ª–∏—Ç—É–¥–∞ —Å–∞–∫–∫–∞–¥',
            'saccades': '–°–∞–∫–∫–∞–¥—ã', 'visited_areas': '–ü–æ—Å–µ—â. –∑–æ–Ω—ã'
        }
        ax.set_title(f"{trial_measure_names.get(measure, measure)}", 
                    fontweight='bold', fontsize=13)
        
        # –ü–æ–¥–ø–∏—Å–∏ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ –±–∞—Ä–∞—Ö
        baseline_mean = np.mean([trial_stats[measure][t]['mean'] for t in [1, 2, 3]])
        for j, (trial, mean_val) in enumerate(zip(trials, means)):
            if trial > 3:  # –¢–æ–ª—å–∫–æ –¥–ª—è —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö —Ç—Ä–∞–π–ª–æ–≤
                change_pct = ((mean_val - baseline_mean) / baseline_mean) * 100
                symbol = "‚Üó" if change_pct > 0 else "‚Üò"
                ax.text(trial, mean_val + stds[j] + max(means) * 0.02, 
                       f'{symbol}{abs(change_pct):.1f}%', 
                       ha='center', va='bottom', fontweight='bold', fontsize=10)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Å–µ–π
        ax.set_xlabel('–ù–æ–º–µ—Ä —Ç—Ä–∞–π–ª–∞')
        ax.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')
        ax.set_xticks(trials)
        ax.grid(True, alpha=0.3)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–µ–Ω–¥—É —Ñ–∞–∑ (—Ç–æ–ª—å–∫–æ –Ω–∞ –ø–µ—Ä–≤–æ–º –≥—Ä–∞—Ñ–∏–∫–µ)
        if i == 0:
            legend_elements = []
            legend_labels = {
                'baseline_1': '–ë–∞–∑–æ–≤–∞—è –ª–∏–Ω–∏—è', 
                'stress_peak': '–ü–∏–∫ —Å—Ç—Ä–µ—Å—Å–∞',
                'stress_adapt': '–ê–¥–∞–ø—Ç–∞—Ü–∏—è', 
                'stress_recovery': '–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ'
            }
            for phase, color in phase_colors.items():
                if phase in legend_labels:
                    legend_elements.append(plt.Rectangle((0,0),1,1, facecolor=color, alpha=0.8))
            
            ax.legend(legend_elements, list(legend_labels.values()), 
                     loc='upper right', fontsize=9)
    
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∏
    for i in range(len(trial_measures), len(axes1)):
        fig1.delaxes(axes1[i])
    
    # –û–±—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    fig1.suptitle('üìä –î–ò–ù–ê–ú–ò–ö–ê –°–¢–†–ï–°–°–ê –ü–û –¢–†–ê–ô–õ–ê–ú (–£–†–û–í–ï–ù–¨ –¢–†–ê–ô–õ–û–í)', 
                 fontsize=18, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.92)
    plt.savefig('results/trial_level_dynamics.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 2. –î–ò–ù–ê–ú–ò–ö–ê –ù–ê –£–†–û–í–ù–ï –°–õ–û–í
    print("üìù –ì—Ä–∞—Ñ–∏–∫–∏ –¥–∏–Ω–∞–º–∏–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤...")
    
    word_measures = list(word_trial_stats.keys())[:8]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 8 –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã
    
    # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à—É—é —Ñ–∏–≥—É—Ä—É –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤
    fig2, axes2 = plt.subplots(3, 3, figsize=(24, 18))
    axes2 = axes2.flatten()
    
    for i, measure in enumerate(word_measures):
        if i >= len(axes2):
            break
        
        ax = axes2[i]
        
        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
        trials = sorted(word_trial_stats[measure].keys())
        means = [word_trial_stats[measure][t]['mean'] for t in trials]
        stds = [word_trial_stats[measure][t]['std'] for t in trials]
        phases = [word_trial_stats[measure][t]['phase'] for t in trials]
        colors = [phase_colors[phase] for phase in phases]
        
        # –°–æ–∑–¥–∞–µ–º bar plot —Å error bars
        bars = ax.bar(trials, means, yerr=stds, capsize=5, 
                     color=colors, alpha=0.8, edgecolor='black', linewidth=1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é —Ç—Ä–µ–Ω–¥–∞
        ax.plot(trials, means, 'k--', alpha=0.7, linewidth=2, marker='o', markersize=6)
        
        # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è —Ä–∞–∑–¥–µ–ª—è—é—â–∞—è —Ñ–∞–∑—ã
        ax.axvline(x=3.5, color='red', linestyle=':', linewidth=2, alpha=0.7)
        ax.text(3.5, max(means) * 0.9, '–ù–ê–ß–ê–õ–û\n–°–¢–†–ï–°–°–ê', ha='center', va='center', 
               bbox=dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.3))
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        ax.set_title(f"{word_measure_names.get(measure, measure)}", 
                    fontweight='bold', fontsize=11)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–Ω–∞—á–∏–º–æ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
        result = word_dynamics_results.get(measure)
        if result:
            significance_text = ""
            if not np.isnan(result['baseline_vs_peak_p']) and result['baseline_vs_peak_p'] < 0.05:
                significance_text += "–ë–∞–∑–∞‚Üî4: ‚úÖ "
            if not np.isnan(result['peak_vs_recovery_p']) and result['peak_vs_recovery_p'] < 0.05:
                significance_text += "4‚Üî6: ‚úÖ"
            
            if significance_text:
                ax.text(0.02, 0.98, significance_text, transform=ax.transAxes,
                       va='top', ha='left', fontsize=9,
                       bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen", alpha=0.7))
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Å–µ–π
        ax.set_xlabel('–ù–æ–º–µ—Ä —Ç—Ä–∞–π–ª–∞')
        ax.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')
        ax.set_xticks(trials)
        ax.grid(True, alpha=0.3)
    
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∏
    for i in range(len(word_measures), len(axes2)):
        fig2.delaxes(axes2[i])
    
    # –û–±—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    fig2.suptitle('üìù –î–ò–ù–ê–ú–ò–ö–ê –°–¢–†–ï–°–°–ê –ü–û –¢–†–ê–ô–õ–ê–ú (–£–†–û–í–ï–ù–¨ –°–õ–û–í)', 
                 fontsize=18, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.92)
    plt.savefig('results/word_level_dynamics.png', dpi=300, bbox_inches='tight')
    plt.show()

def create_comprehensive_visualizations(trial_data, comparison_results, dynamics):
    """
    –°–æ–∑–¥–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞
    """
    print(f"\nüé® –°–û–ó–î–ê–ù–ò–ï –ö–û–ú–ü–õ–ï–ö–°–ù–´–• –ì–†–ê–§–ò–ö–û–í")
    print("=" * 50)
    
    # 1. –°–†–ê–í–ù–ï–ù–ò–ï –£–°–õ–û–í–ò–ô (–ë–ï–ó –°–¢–†–ï–°–°–ê VS –°–û –°–¢–†–ï–°–°–û–ú)
    fig, axes = plt.subplots(2, 5, figsize=(25, 12))
    axes = axes.flatten()
    
    for i, result in enumerate(comparison_results[:10]):
        if i >= len(axes):
            break
            
        ax = axes[i]
        measure = result['measure']
        
        # –î–∞–Ω–Ω—ã–µ –¥–ª—è boxplot
        no_stress_data = trial_data[trial_data['condition'] == 'no_stress'][measure]
        stress_data = trial_data[trial_data['condition'] == 'stress'][measure]
        
        # –°–æ–∑–¥–∞–µ–º boxplot
        bp = ax.boxplot([no_stress_data, stress_data], 
                       labels=['–ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞\n(–¢1-3)', '–°–æ —Å—Ç—Ä–µ—Å—Å–æ–º\n(–¢4-6)'],
                       patch_artist=True, widths=0.6)
        
        # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º
        bp['boxes'][0].set_facecolor('#2E86C1')
        bp['boxes'][0].set_alpha(0.7)
        bp['boxes'][1].set_facecolor('#E74C3C')
        bp['boxes'][1].set_alpha(0.7)
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        ax.set_title(f"{result['measure_name']}", fontweight='bold', fontsize=11)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ
        change_pct = result['change_percent']
        symbol = "‚Üó" if change_pct > 0 else "‚Üò"
        ax.text(0.5, 0.95, f'{symbol}{abs(change_pct):.1f}%', 
               transform=ax.transAxes, ha='center', va='top',
               fontweight='bold', fontsize=12)
        
        # –ó–Ω–∞—á–∏–º–æ—Å—Ç—å
        if result['significant']:
            significance_text = f"p = {result['p_value']:.3f} ‚úÖ"
            bbox_color = 'lightgreen'
        else:
            significance_text = f"p = {result['p_value']:.3f}" if not np.isnan(result['p_value']) else "n.s."
            bbox_color = 'lightgray'
        
        ax.text(0.5, 0.02, significance_text, transform=ax.transAxes,
               ha='center', va='bottom', fontsize=9,
               bbox=dict(boxstyle="round,pad=0.3", facecolor=bbox_color, alpha=0.7))
        
        ax.grid(True, alpha=0.3)
    
    plt.suptitle('üß† –°–†–ê–í–ù–ï–ù–ò–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ï–ô –ê–ô–¢–†–ï–ö–ò–ù–ì–ê: –ë–ï–ó –°–¢–†–ï–°–°–ê vs –°–û –°–¢–†–ï–°–°–û–ú', 
                 fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.savefig('results/comprehensive_stress_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 2. –î–ò–ù–ê–ú–ò–ö–ê –ü–û –¢–†–ê–ô–õ–ê–ú
    fig, axes = plt.subplots(2, 4, figsize=(20, 12))
    axes = axes.flatten()
    
    measures_for_dynamics = list(dynamics.keys())[:8]
    
    colors = ['#3498DB', '#5DADE2', '#85C1E9', '#E74C3C', '#F1948A', '#F8C471']
    
    for i, measure in enumerate(measures_for_dynamics):
        ax = axes[i]
        
        values = dynamics[measure]['values']
        phases = dynamics[measure]['phases']
        
        # –°–æ–∑–¥–∞–µ–º –ª–∏–Ω–µ–π–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫
        trials = list(range(1, 7))
        ax.plot(trials, values, 'o-', linewidth=3, markersize=8, color='darkblue')
        
        # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º —Ç–æ—á–∫–∏ –ø–æ —Ñ–∞–∑–∞–º
        phase_colors = {
            'baseline_1': '#3498DB', 'baseline_2': '#5DADE2', 'baseline_3': '#85C1E9',
            'stress_peak': '#E74C3C', 'stress_adapt': '#F1948A', 'stress_recovery': '#F8C471'
        }
        
        for j, (trial, value, phase) in enumerate(zip(trials, values, phases)):
            ax.scatter(trial, value, s=150, c=phase_colors.get(phase, 'gray'), 
                      edgecolor='black', linewidth=2, zorder=5)
        
        # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è —Ä–∞–∑–¥–µ–ª—è—é—â–∞—è —Ñ–∞–∑—ã
        ax.axvline(x=3.5, color='red', linestyle='--', alpha=0.7, linewidth=2)
        ax.text(3.5, max(values) * 0.9, '–ù–ê–ß–ê–õ–û\n–°–¢–†–ï–°–°–ê', ha='center', va='center',
               bbox=dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.3))
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
        measure_name = {
            'blinks': '–ú–æ—Ä–≥–∞–Ω–∏—è', 'fixations': '–§–∏–∫—Å–∞—Ü–∏–∏', 
            'fixation_duration_mean': '–î–ª–∏—Ç. —Ñ–∏–∫—Å–∞—Ü–∏–π', 'pupil_size': '–†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞',
            'runs': '–ó–∞–±–µ–≥–∞–Ω–∏—è', 'saccade_amplitude_mean': '–ê–º–ø–ª–∏—Ç—É–¥–∞ —Å–∞–∫–∫–∞–¥',
            'saccades': '–°–∞–∫–∫–∞–¥—ã', 'visited_areas': '–ü–æ—Å–µ—â. –∑–æ–Ω—ã'
        }.get(measure, measure)
        
        ax.set_title(f"{measure_name}\n{dynamics[measure]['pattern']}", 
                    fontweight='bold', fontsize=10)
        
        ax.set_xlabel('–ù–æ–º–µ—Ä —Ç—Ä–∞–π–ª–∞')
        ax.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')
        ax.set_xticks(trials)
        ax.grid(True, alpha=0.3)
    
    plt.suptitle('üìä –î–ò–ù–ê–ú–ò–ö–ê –ü–û–ö–ê–ó–ê–¢–ï–õ–ï–ô –ê–ô–¢–†–ï–ö–ò–ù–ì–ê –ü–û –¢–†–ê–ô–õ–ê–ú', 
                 fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.savefig('results/comprehensive_trial_dynamics.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 3. –°–ü–ï–¶–ò–ê–õ–¨–ù–´–ô –ì–†–ê–§–ò–ö: –ö–õ–Æ–ß–ï–í–´–ï –ú–ê–†–ö–ï–†–´ –°–¢–†–ï–°–°–ê
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    # –°–∞–º—ã–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
    key_measures = ['pupil_size', 'blinks', 'saccade_amplitude_mean']
    key_names = ['–†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞ (—Å—Ç—Ä–µ—Å—Å-–º–∞—Ä–∫–µ—Ä)', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ—Ä–≥–∞–Ω–∏–π', '–ê–º–ø–ª–∏—Ç—É–¥–∞ —Å–∞–∫–∫–∞–¥']
    
    for i, (measure, name) in enumerate(zip(key_measures, key_names)):
        ax = axes[i]
        
        no_stress = trial_data[trial_data['condition'] == 'no_stress'][measure]
        stress = trial_data[trial_data['condition'] == 'stress'][measure]
        
        # Violin plot –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã
        violin = ax.violinplot([no_stress, stress], positions=[1, 2], widths=0.5)
        ax.scatter([1] * len(no_stress), no_stress, alpha=0.7, s=100, color='blue', label='–ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞')
        ax.scatter([2] * len(stress), stress, alpha=0.7, s=100, color='red', label='–°–æ —Å—Ç—Ä–µ—Å—Å–æ–º')
        
        # –°—Ä–µ–¥–Ω–∏–µ –ª–∏–Ω–∏–∏
        ax.hlines(no_stress.mean(), 0.7, 1.3, colors='blue', linestyle='--', linewidth=2)
        ax.hlines(stress.mean(), 1.7, 2.3, colors='red', linestyle='--', linewidth=2)
        
        ax.set_title(name, fontweight='bold')
        ax.set_xticks([1, 2])
        ax.set_xticklabels(['–ë–µ–∑ —Å—Ç—Ä–µ—Å—Å–∞', '–°–æ —Å—Ç—Ä–µ—Å—Å–æ–º'])
        ax.grid(True, alpha=0.3)
        
        if i == 0:
            ax.legend()
    
    plt.suptitle('üéØ –ö–õ–Æ–ß–ï–í–´–ï –ú–ê–†–ö–ï–†–´ –°–¢–†–ï–°–°–ê –í –î–ê–ù–ù–´–• –ê–ô–¢–†–ï–ö–ò–ù–ì–ê', 
                 fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.subplots_adjust(top=0.85)
    plt.savefig('results/key_stress_markers.png', dpi=300, bbox_inches='tight')
    plt.show()

def test_formal_hypotheses(word_comparison_results, trial_comparison_results):
    """
    –ü—Ä–æ–≤–æ–¥–∏—Ç —Ñ–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—É—á–Ω—ã—Ö –≥–∏–ø–æ—Ç–µ–∑ —Å –≤—ã–≤–æ–¥–∞–º–∏
    """
    print(f"\nüî¨ –§–û–†–ú–ê–õ–¨–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ì–ò–ü–û–¢–ï–ó")
    print("=" * 80)
    
    # –ü–æ–¥—Å—á–µ—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    word_significant = [r for r in word_comparison_results if r['significant']]
    trial_significant = [r for r in trial_comparison_results if r['significant']]
    total_significant = len(word_significant) + len(trial_significant)
    total_tests = len(word_comparison_results) + len(trial_comparison_results)
    
    print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print(f"   ‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {total_tests}")
    print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (p < 0.05): {total_significant}")
    print(f"   ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {total_significant/total_tests*100:.1f}%")
    
    print(f"\n‚öñÔ∏è –ü–†–û–í–ï–†–ö–ê –ì–ò–ü–û–¢–ï–ó –ü–û –£–†–û–í–ù–Ø–ú –ê–ù–ê–õ–ò–ó–ê:")
    
    # –ê–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω—è —Å–ª–æ–≤
    print(f"\n   üìù –£–†–û–í–ï–ù–¨ –°–õ–û–í (N = 548 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π):")
    print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {len(word_comparison_results)}")
    print(f"   ‚Ä¢ –ó–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(word_significant)}")
    
    if len(word_significant) > 0:
        print(f"   üîπ –í–´–í–û–î: H0 –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø –ø–æ {len(word_significant)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª—é(—è–º)")
        for result in word_significant:
            print(f"      ‚úÖ {result['measure_name']}: p = {result['p_value']:.4f} < 0.05")
    else:
        print(f"   üî∏ –í–´–í–û–î: H0 –ù–ï –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø (–Ω–µ—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Ä–∞–∑–ª–∏—á–∏–π)")
    
    # –ê–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω—è —Ç—Ä–∞–π–ª–æ–≤
    print(f"\n   üìä –£–†–û–í–ï–ù–¨ –¢–†–ê–ô–õ–û–í (N = 6 —Ç—Ä–∞–π–ª–æ–≤):")
    print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {len(trial_comparison_results)}")
    print(f"   ‚Ä¢ –ó–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(trial_significant)}")
    
    if len(trial_significant) > 0:
        print(f"   üîπ –í–´–í–û–î: H0 –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø –ø–æ {len(trial_significant)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª—é(—è–º)")
        for result in trial_significant:
            print(f"      ‚úÖ {result['measure_name']}: p = {result['p_value']:.4f} < 0.05")
    else:
        print(f"   üî∏ –í–´–í–û–î: H0 –ù–ï –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø (–Ω–µ—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Ä–∞–∑–ª–∏—á–∏–π)")
        print(f"   ‚ö†Ô∏è  –ü–†–ò–ß–ò–ù–ê: –ú–∞–ª—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ (N = 6)")
        
        # –ù–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
        large_effects = [r for r in trial_comparison_results if abs(r['cohens_d']) >= 0.8]
        print(f"   üìà –û–î–ù–ê–ö–û: –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(large_effects)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å –ë–û–õ–¨–®–ò–ú–ò —Ä–∞–∑–º–µ—Ä–∞–º–∏ —ç—Ñ—Ñ–µ–∫—Ç–∞")
    
    # –û–ë–©–ï–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –ü–û –ì–ò–ü–û–¢–ï–ó–ê–ú
    print(f"\nüèõÔ∏è –ò–¢–û–ì–û–í–û–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –ü–û –ì–ò–ü–û–¢–ï–ó–ê–ú:")
    
    if total_significant > 0:
        print(f"   ‚úÖ –ù–£–õ–ï–í–ê–Ø –ì–ò–ü–û–¢–ï–ó–ê H0 –ß–ê–°–¢–ò–ß–ù–û –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø")
        print(f"   ‚úÖ –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–ê–Ø –ì–ò–ü–û–¢–ï–ó–ê H1 –ß–ê–°–¢–ò–ß–ù–û –ü–û–î–¢–í–ï–†–ñ–î–ê–ï–¢–°–Ø") 
        print(f"   üéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï: –°—É—â–µ—Å—Ç–≤—É—é—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è")
        print(f"      –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞ –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏ —Å—Ç—Ä–µ—Å—Å–∞")
    else:
        print(f"   üî∏ –ù–£–õ–ï–í–ê–Ø –ì–ò–ü–û–¢–ï–ó–ê H0 –ù–ï –û–¢–ö–õ–û–ù–Ø–ï–¢–°–Ø –Ω–∞ —É—Ä–æ–≤–Ω–µ p < 0.05")
        print(f"   ‚ö†Ô∏è  –û–î–ù–ê–ö–û: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ë–û–õ–¨–®–ò–ï —Ä–∞–∑–º–µ—Ä—ã —ç—Ñ—Ñ–µ–∫—Ç–æ–≤")
        
        # –ü–æ–¥—Å—á–µ—Ç –±–æ–ª—å—à–∏—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
        all_large_effects = [r for r in word_comparison_results + trial_comparison_results 
                           if abs(r['cohens_d']) >= 0.8]
        
        print(f"   üìä –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ê–Ø –ó–ù–ê–ß–ò–ú–û–°–¢–¨: {len(all_large_effects)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å d > 0.8")
        print(f"   üî¨ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–∞–ª—å–Ω–µ–π—à–∏–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º
    print(f"\nüìã –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –î–ê–õ–¨–ù–ï–ô–®–ò–• –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ô:")
    
    if total_significant == 0:
        print(f"   1. –£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–æ N ‚â• 30 —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
        print(f"   2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–µ —Å—Ç—Ä–µ—Å—Å–æ–≤—ã–µ —Å—Ç–∏–º—É–ª—ã")
        print(f"   3. –ü—Ä–æ–≤–µ—Å—Ç–∏ power-–∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π –≤—ã–±–æ—Ä–∫–∏")
    
    print(f"   4. –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ü–∏—é –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (Bonferroni)")
    print(f"   5. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –º–∞–ª—ã—Ö –≤—ã–±–æ—Ä–æ–∫")
    print(f"   6. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤ –∫–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–µ—Å—Å–∞")
    
    return total_significant, total_tests

def generate_comprehensive_report(word_comparison_results, trial_comparison_results, dynamics):
    """
    –°–æ–∑–¥–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å—Ç—Ä–µ—Å—Å–∞ —á–µ—Ä–µ–∑ –∞–π—Ç—Ä–µ–∫–∏–Ω–≥
    """
    print(f"\nüèÜ –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢: –î–ï–¢–ï–ö–¶–ò–Ø –°–¢–†–ï–°–°–ê –ß–ï–†–ï–ó –ê–ô–¢–†–ï–ö–ò–ù–ì")
    print("=" * 80)
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤
    word_significant_results = [r for r in word_comparison_results if r['significant']]
    word_large_effects = [r for r in word_comparison_results if abs(r['cohens_d']) >= 0.8]
    word_medium_effects = [r for r in word_comparison_results if 0.5 <= abs(r['cohens_d']) < 0.8]
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç—Ä–∞–π–ª–æ–≤
    trial_significant_results = [r for r in trial_comparison_results if r['significant']]
    trial_large_effects = [r for r in trial_comparison_results if abs(r['cohens_d']) >= 0.8]
    trial_medium_effects = [r for r in trial_comparison_results if 0.5 <= abs(r['cohens_d']) < 0.8]
    
    print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó:")
    print(f"\n   üìù –£–†–û–í–ï–ù–¨ –°–õ–û–í (N = 548 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π):")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π: {len(word_comparison_results)}")
    print(f"   ‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ä–∞–∑–ª–∏—á–∏–π: {len(word_significant_results)}")
    print(f"   ‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç—ã –±–æ–ª—å—à–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞: {len(word_large_effects)}")
    print(f"   ‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç—ã —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞: {len(word_medium_effects)}")
    
    print(f"\n   üìä –£–†–û–í–ï–ù–¨ –¢–†–ê–ô–õ–û–í (N = 6 —Ç—Ä–∞–π–ª–æ–≤):")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π: {len(trial_comparison_results)}")
    print(f"   ‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ä–∞–∑–ª–∏—á–∏–π: {len(trial_significant_results)}")
    print(f"   ‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç—ã –±–æ–ª—å—à–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞: {len(trial_large_effects)}")
    print(f"   ‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç—ã —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞: {len(trial_medium_effects)}")
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–∞–º—ã—Ö –∑–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    all_significant = word_significant_results + trial_significant_results
    all_large_effects = word_large_effects + trial_large_effects
    
    if all_significant:
        print(f"\n‚úÖ –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò –ó–ù–ê–ß–ò–ú–´–ï –†–ê–ó–õ–ò–ß–ò–Ø:")
        for result in all_significant:
            if 'change_absolute' in result:  # –¢—Ä–∞–π–ª—ã
                direction = "–≤—ã—à–µ" if result['change_absolute'] > 0 else "–Ω–∏–∂–µ"
                print(f"   üéØ {result['measure_name']}: {direction} –Ω–∞ {abs(result['change_percent']):.1f}%")
                print(f"      p = {result['p_value']:.3f}, Cohen's d = {result['cohens_d']:.3f}")
            else:  # –°–ª–æ–≤–∞
                direction = result['change_direction']
                print(f"   üéØ {result['measure_name']}: {direction} –Ω–∞ {abs(result['change_percent']):.1f}%")
                print(f"      p = {result['p_value']:.3f}, Cohen's d = {result['cohens_d']:.3f}")
    
    print(f"\nüìà –ù–ê–ë–õ–Æ–î–ê–ï–ú–´–ï –ò–ó–ú–ï–ù–ï–ù–ò–Ø –ü–û–î –í–õ–ò–Ø–ù–ò–ï–ú –°–¢–†–ï–°–°–ê:")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
    all_increases = []
    all_decreases = []
    
    for result in word_comparison_results + trial_comparison_results:
        if 'change_absolute' in result:  # –¢—Ä–∞–π–ª—ã
            if result['change_absolute'] > 0:
                all_increases.append(result)
            else:
                all_decreases.append(result)
        else:  # –°–ª–æ–≤–∞
            if result['change_direction'] == '—É–≤–µ–ª–∏—á–µ–Ω–∏–µ':
                all_increases.append(result)
            else:
                all_decreases.append(result)
    
    if all_increases:
        print(f"\n   ‚¨ÜÔ∏è –£–í–ï–õ–ò–ß–ï–ù–ò–ï:")
        for result in sorted(all_increases, key=lambda x: abs(x['change_percent']), reverse=True)[:10]:
            significance = " ‚úÖ" if result['significant'] else ""
            print(f"      ‚Ä¢ {result['measure_name']}: +{abs(result['change_percent']):.1f}%{significance}")
    
    if all_decreases:
        print(f"\n   ‚¨áÔ∏è –£–ú–ï–ù–¨–®–ï–ù–ò–ï:")
        for result in sorted(all_decreases, key=lambda x: abs(x['change_percent']), reverse=True)[:10]:
            significance = " ‚úÖ" if result['significant'] else ""
            print(f"      ‚Ä¢ {result['measure_name']}: {result['change_percent']:.1f}%{significance}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–∏–Ω–∞–º–∏–∫–∏
    print(f"\nüîÑ –ê–ù–ê–õ–ò–ó –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–• –ü–ê–¢–¢–ï–†–ù–û–í:")
    
    peak_patterns = 0
    recovery_patterns = 0
    
    for measure, data in dynamics.items():
        if "–ü–ò–ö –≤ –¢4" in data['pattern']:
            peak_patterns += 1
            if "–í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï" in data['pattern']:
                recovery_patterns += 1
    
    print(f"   ‚Ä¢ –ü–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å –ø–∏–∫–æ–º –≤ —Ç—Ä–∞–π–ª–µ 4: {peak_patterns}/{len(dynamics)}")
    print(f"   ‚Ä¢ –ü–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º: {recovery_patterns}/{len(dynamics)}")
    
    # –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´
    print(f"\nüß† –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´ –û –î–ï–¢–ï–ö–¶–ò–ò –°–¢–†–ï–°–°–ê:")
    
    total_significant = len(all_significant)
    total_large_effects = len(all_large_effects)
    
    if total_significant > 0 or total_large_effects > 5:
        print("   ‚úÖ –°–¢–†–ï–°–° –î–ï–¢–ï–ö–¢–ò–†–£–ï–¢–°–Ø —á–µ—Ä–µ–∑ –∞–π—Ç—Ä–µ–∫–∏–Ω–≥!")
        print("   üéØ –õ—É—á—à–∏–µ –º–∞—Ä–∫–µ—Ä—ã –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏:")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        best_results = all_significant + all_large_effects
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É —ç—Ñ—Ñ–µ–∫—Ç–∞
        unique_results = {r['measure_name']: r for r in best_results}.values()
        sorted_results = sorted(unique_results, key=lambda x: abs(x['cohens_d']), reverse=True)
        
        for result in sorted_results[:5]:
            level = "—Å–ª–æ–≤–∞" if 'change_direction' in result else "—Ç—Ä–∞–π–ª—ã"
            print(f"      ‚Ä¢ {result['measure_name']} (—É—Ä–æ–≤–µ–Ω—å: {level})")
        
    else:
        print("   ‚ö†Ô∏è  –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ä–∞–∑–ª–∏—á–∏–π –º–∞–ª–æ")
        print("   üìä –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        print("      ‚Ä¢ –ú–∞–ª—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏")
        print("      ‚Ä¢ –í—ã—Å–æ–∫–∞—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å")
        print("      ‚Ä¢ –ë—ã—Å—Ç—Ä–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ —Å—Ç—Ä–µ—Å—Å—É")
    
    print(f"\nüîç –ù–ê–ò–ë–û–õ–ï–ï –ü–ï–†–°–ü–ï–ö–¢–ò–í–ù–´–ï –ú–ê–†–ö–ï–†–´ (–ø–æ —Ä–∞–∑–º–µ—Ä—É —ç—Ñ—Ñ–µ–∫—Ç–∞):")
    
    all_effects = sorted(word_comparison_results + trial_comparison_results, 
                        key=lambda x: abs(x['cohens_d']), reverse=True)
    
    for i, result in enumerate(all_effects[:8], 1):
        effect_description = "–±–æ–ª—å—à–æ–π" if abs(result['cohens_d']) >= 0.8 else "—Å—Ä–µ–¥–Ω–∏–π" if abs(result['cohens_d']) >= 0.5 else "–º–∞–ª—ã–π"
        level = "—Å–ª–æ–≤–∞" if 'change_direction' in result else "—Ç—Ä–∞–π–ª—ã"
        print(f"   {i}. {result['measure_name']} ({level}): {effect_description} —ç—Ñ—Ñ–µ–∫—Ç (d = {result['cohens_d']:.3f})")
    
    # –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
    print(f"\nüí° –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    
    if total_significant > 0 or total_large_effects > 3:
        print("   ‚úÖ –ê–ô–¢–†–ï–ö–ò–ù–ì –ú–û–ñ–ï–¢ –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨–°–Ø –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å—Ç—Ä–µ—Å—Å–∞")
        print("   üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:")
        key_measures = (all_significant + all_large_effects)[:5]
        for result in key_measures:
            level = "—Å–ª–æ–≤–∞" if 'change_direction' in result else "—Ç—Ä–∞–π–ª—ã"
            print(f"      ‚Ä¢ {result['measure_name']} (—É—Ä–æ–≤–µ–Ω—å: {level})")
        print("   üìä –ù–µ–æ–±—Ö–æ–¥–∏–º—ã:")
        print("      ‚Ä¢ –ë–æ–ª—å—à–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è")
        print("      ‚Ä¢ –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –±–∞–∑–æ–≤—ã–µ –ª–∏–Ω–∏–∏")
        print("      ‚Ä¢ –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è (—Ñ–∏–∑–∏–æ–ª–æ–≥–∏—è + –∞–π—Ç—Ä–µ–∫–∏–Ω–≥)")
        print("      ‚Ä¢ –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π")
    else:
        print("   üìä –î–õ–Ø –ù–ê–î–ï–ñ–ù–û–ô –î–ï–¢–ï–ö–¶–ò–ò –°–¢–†–ï–°–°–ê –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ:")
        print("      ‚Ä¢ –£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ (>10 —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤)")
        print("      ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–µ —Å—Ç—Ä–µ—Å—Å–æ–≤—ã–µ —É—Å–ª–æ–≤–∏—è")
        print("      ‚Ä¢ –î–æ–±–∞–≤–∏—Ç—å —Ñ–∏–∑–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –º–∞—Ä–∫–µ—Ä—ã")
        print("      ‚Ä¢ –ü—Ä–∏–º–µ–Ω–∏—Ç—å –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")
    
    print(f"\nüöÄ –†–ï–ó–Æ–ú–ï:")
    print(f"   ‚Ä¢ –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(word_comparison_results) + len(trial_comparison_results)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞")
    print(f"   ‚Ä¢ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {total_large_effects} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å –±–æ–ª—å—à–∏–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏ —ç—Ñ—Ñ–µ–∫—Ç–∞")
    print(f"   ‚Ä¢ {recovery_patterns} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –∞–¥–∞–ø—Ç–∞—Ü–∏—é –∫ —Å—Ç—Ä–µ—Å—Å—É")
    print(f"   ‚Ä¢ –ê–π—Ç—Ä–µ–∫–∏–Ω–≥ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç {'–≤—ã—Å–æ–∫–∏–π' if total_large_effects > 5 else '—Å—Ä–µ–¥–Ω–∏–π' if total_large_effects > 2 else '–Ω–∏–∑–∫–∏–π'} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å—Ç—Ä–µ—Å—Å–∞")

def print_research_hypotheses():
    """
    –ü–µ—á–∞—Ç–∞–µ—Ç —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–µ –Ω–∞—É—á–Ω—ã–µ –≥–∏–ø–æ—Ç–µ–∑—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    """
    print("üî¨ –ù–ê–£–ß–ù–´–ï –ì–ò–ü–û–¢–ï–ó–´ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø")
    print("=" * 80)
    
    print("\nüìã –§–û–†–ú–£–õ–ò–†–û–í–ö–ê –ì–ò–ü–û–¢–ï–ó:")
    
    print("\nüî∏ –ù–£–õ–ï–í–ê–Ø –ì–ò–ü–û–¢–ï–ó–ê (H0):")
    print("   –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞")
    print("   –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏ –ë–ï–ó –°–¢–†–ï–°–°–ê (—Ç—Ä–∞–π–ª—ã 1-3) –∏ –°–û –°–¢–†–ï–°–°–û–ú (—Ç—Ä–∞–π–ª—ã 4-6)")
    print("   H0: Œº‚ÇÅ = Œº‚ÇÇ (—Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ä–∞–≤–Ω—ã)")
    
    print("\nüîπ –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–ê–Ø –ì–ò–ü–û–¢–ï–ó–ê (H1):")
    print("   –°—É—â–µ—Å—Ç–≤—É—é—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞")
    print("   –º–µ–∂–¥—É —É—Å–ª–æ–≤–∏—è–º–∏ –ë–ï–ó –°–¢–†–ï–°–°–ê –∏ –°–û –°–¢–†–ï–°–°–û–ú")
    print("   H1: Œº‚ÇÅ ‚â† Œº‚ÇÇ (—Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è)")
    
    print("\n‚öñÔ∏è –ö–†–ò–¢–ï–†–ò–ò –ü–†–ò–ù–Ø–¢–ò–Ø –†–ï–®–ï–ù–ò–Ø:")
    print("   ‚Ä¢ –£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏: Œ± = 0.05")
    print("   ‚Ä¢ –ï—Å–ª–∏ p-value < 0.05 ‚Üí –û–¢–ö–õ–û–ù–Ø–ï–ú H0, –ü–†–ò–ù–ò–ú–ê–ï–ú H1")
    print("   ‚Ä¢ –ï—Å–ª–∏ p-value ‚â• 0.05 ‚Üí –ù–ï –û–¢–ö–õ–û–ù–Ø–ï–ú H0")
    
    print("\nüß™ –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ï –ú–ï–¢–û–î–´:")
    print("   ‚Ä¢ –ö—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏ (–Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π)")
    print("   ‚Ä¢ t-–∫—Ä–∏—Ç–µ—Ä–∏–π –°—Ç—å—é–¥–µ–Ω—Ç–∞ (–ø—Ä–∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏)")
    print("   ‚Ä¢ –†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞: Cohen's d")
    
    print("\nüìä –û–ñ–ò–î–ê–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print("   –ï—Å–ª–∏ H1 –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è ‚Üí –∞–π—Ç—Ä–µ–∫–∏–Ω–≥ –º–æ–∂–µ—Ç –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–µ—Å—Å")
    print("   –ï—Å–ª–∏ H0 –Ω–µ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è ‚Üí –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")

def main():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞
    """
    print("üöÄ –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• –ê–ô–¢–†–ï–ö–ò–ù–ì–ê")
    print("üéØ –¶–µ–ª—å: –î–æ–∫–∞–∑–∞—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å—Ç—Ä–µ—Å—Å–∞ —á–µ—Ä–µ–∑ –¥–≤–∏–∂–µ–Ω–∏—è –≥–ª–∞–∑")
    print("üìä –ê–Ω–∞–ª–∏–∑ –Ω–∞ –¥–≤—É—Ö —É—Ä–æ–≤–Ω—è—Ö: –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ + —Ü–µ–ª—ã–µ —Ç—Ä–∞–π–ª—ã")
    print("=" * 80)
    
    # –§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –Ω–∞—É—á–Ω—ã—Ö –≥–∏–ø–æ—Ç–µ–∑
    print_research_hypotheses()
    
    try:
        # 0. –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        ensure_results_directory()
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        word_data, trial_data, word_measure_names = load_comprehensive_data()
        
        # 2. –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤
        word_comparison_results = analyze_word_level_differences(word_data, word_measure_names)
        
        # 3. –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç—Ä–∞–π–ª–æ–≤
        trial_comparison_results = analyze_trial_level_differences(trial_data)
        
        # 4. –ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç—Ä–∞–π–ª–æ–≤
        dynamics, trial_stats = analyze_trial_dynamics(trial_data)
        
        # 5. –ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤
        word_trial_stats, word_dynamics_results = analyze_word_dynamics(word_data, word_measure_names)
        
        # 6. –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
        # 6a. –ì—Ä–∞—Ñ–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —É—Å–ª–æ–≤–∏–π –¥–ª—è —Å–ª–æ–≤
        create_enhanced_word_visualizations(word_data, word_comparison_results, word_measure_names)
        
        # 6b. –ì—Ä–∞—Ñ–∏–∫–∏ –¥–∏–Ω–∞–º–∏–∫–∏ –¥–ª—è –æ–±–æ–∏—Ö —É—Ä–æ–≤–Ω–µ–π
        create_dynamics_visualizations(trial_data, trial_stats, word_data, word_trial_stats, 
                                     word_dynamics_results, word_measure_names)
        
        # 6c. –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç—Ä–∞–π–ª–æ–≤
        create_comprehensive_visualizations(trial_data, trial_comparison_results, dynamics)
        
        # 7. –§–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–∏–ø–æ—Ç–µ–∑
        total_significant, total_tests = test_formal_hypotheses(word_comparison_results, trial_comparison_results)
        
        # 8. –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        generate_comprehensive_report(word_comparison_results, trial_comparison_results, dynamics)
        
        print(f"\nüéâ –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        print(f"üìä –°–æ–∑–¥–∞–Ω–æ 6 –Ω–∞–±–æ—Ä–æ–≤ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤ –ø–∞–ø–∫–µ 'results/':")
        print(f"   ‚Ä¢ results/word_level_stress_analysis.png - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —É—Å–ª–æ–≤–∏–π (—Å–ª–æ–≤–∞)")
        print(f"   ‚Ä¢ results/trial_level_dynamics.png - –¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ —Ç—Ä–∞–π–ª–∞–º")
        print(f"   ‚Ä¢ results/word_level_dynamics.png - –¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ —Å–ª–æ–≤–∞–º")
        print(f"   ‚Ä¢ results/comprehensive_stress_comparison.png - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —É—Å–ª–æ–≤–∏–π")
        print(f"   ‚Ä¢ results/comprehensive_trial_dynamics.png - –¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ —Ç—Ä–∞–π–ª–∞–º")
        print(f"   ‚Ä¢ results/key_stress_markers.png - –∫–ª—é—á–µ–≤—ã–µ –º–∞—Ä–∫–µ—Ä—ã —Å—Ç—Ä–µ—Å—Å–∞")
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≥–∏–ø–æ—Ç–µ–∑
        print(f"\nüî¨ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ì–ò–ü–û–¢–ï–ó:")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}")
        print(f"   ‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {total_significant}")
        
        if total_significant > 0:
            print(f"   ‚úÖ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï: H0 —á–∞—Å—Ç–∏—á–Ω–æ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è ‚Üí H1 –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è")
            print(f"   üéØ –ê–ô–¢–†–ï–ö–ò–ù–ì –ú–û–ñ–ï–¢ –î–ï–¢–ï–ö–¢–ò–†–û–í–ê–¢–¨ –°–¢–†–ï–°–°!")
        else:
            large_effects = len([r for r in word_comparison_results + trial_comparison_results if abs(r['cohens_d']) >= 0.8])
            if large_effects > 5:
                print(f"   üî∏ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï: H0 –Ω–µ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è, –ù–û –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –±–æ–ª—å—à–∏–µ —ç—Ñ—Ñ–µ–∫—Ç—ã")
                print(f"   üìä –ü–û–¢–ï–ù–¶–ò–ê–õ –î–õ–Ø –î–ï–¢–ï–ö–¶–ò–ò –°–¢–†–ï–°–°–ê –í–´–°–û–ö–ò–ô (–ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ –≤—ã–±–æ—Ä–∫–∏)")
            else:
                print(f"   üî∏ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï: H0 –Ω–µ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è")
                print(f"   üìä –ü–û–¢–ï–ù–¶–ò–ê–õ –î–õ–Ø –î–ï–¢–ï–ö–¶–ò–ò –°–¢–†–ï–°–°–ê –°–†–ï–î–ù–ò–ô")
        
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 
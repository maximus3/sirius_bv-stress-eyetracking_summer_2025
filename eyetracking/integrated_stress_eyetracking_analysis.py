#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞ —Å —É—á–µ—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å—Ç—Ä–µ—Å—Å–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–µ—Å—Å–∞ –∏–∑ –ø–æ–ª–∏–≥—Ä–∞—Ñ–∞ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
—É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–∞ —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö –∏ –Ω–µ—Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö, –∞ –∑–∞—Ç–µ–º –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö —á—Ç–µ–Ω–∏—è.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pathlib
import warnings
from scipy import stats
from scipy.stats import ttest_ind, mannwhitneyu

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ matplotlib –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
plt.rcParams['font.family'] = ['Arial Unicode MS', 'Tahoma', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('default')

# –ü–æ–¥–∞–≤–ª—è–µ–º warnings
warnings.filterwarnings('ignore')

class IntegratedStressEyetrackingAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–µ—Å—Å–∞ –∏ –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞"""
    
    def __init__(self, eyetracking_data_path="eyetracking/by_person/data/trial.xls"):
        self.eyetracking_data_path = pathlib.Path(eyetracking_data_path)
        self.results_dir = pathlib.Path("eyetracking/stress_integrated_results")
        self.results_dir.mkdir(exist_ok=True)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–µ—Å—Å–∞ –∏–∑ –ø–æ–ª–∏–≥—Ä–∞—Ñ–∞
        self.stress_responders = {
            # –£—á–∞—Å—Ç–Ω–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–ª–∏ –Ω–∞ —Å—Ç—Ä–µ—Å—Å (–∏–∑ –ø–æ–ª–∏–≥—Ä–∞—Ñ–∞)
            '1707LTA': {'type': 'strong_responder', 'peak_text': 4, 'description': '–°–∞–º–∞—è —è—Ä–∫–∞—è —Ä–µ–∞–∫—Ü–∏—è (+31.8%)'},
            '1807KNV': {'type': 'strong_responder', 'peak_text': 4, 'description': '–†–µ–∑–∫–∏–π –ø–∏–∫ –≤ 4-–º —Ç–µ–∫—Å—Ç–µ (+150%)'},
            '1607KYA': {'type': 'moderate_responder', 'peak_text': 4, 'description': '–£–º–µ—Ä–µ–Ω–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è'},
            '1807OVA': {'type': 'moderate_responder', 'peak_text': 4, 'description': '–£–º–µ—Ä–µ–Ω–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è'},
            '1807ZUG': {'type': 'weak_responder', 'peak_text': 5, 'description': '–°–ª–∞–±–∞—è —Ä–µ–∞–∫—Ü–∏—è'},
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª–∏–≥—Ä–∞—Ñ–∞
            '1807SAV': {'type': 'assumed_responder', 'peak_text': 4, 'description': '–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π —Å—Ç—Ä–µ—Å—Å –≤ 4-–º —Ç–µ–∫—Å—Ç–µ'},
            '1807KAN': {'type': 'assumed_responder', 'peak_text': 4, 'description': '–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π —Å—Ç—Ä–µ—Å—Å –≤ 4-–º —Ç–µ–∫—Å—Ç–µ'},
        }
        
        self.stress_non_responders = {
            # –£—á–∞—Å—Ç–Ω–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–ª–∏ –Ω–∞ —Å—Ç—Ä–µ—Å—Å (–∏–∑ –ø–æ–ª–∏–≥—Ä–∞—Ñ–∞)
            '1707KAV': {'type': 'strong_non_responder', 'description': '–°–∏–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ —Å—Ç—Ä–µ—Å—Å–∞ (-60%)'},
            '1807HEE': {'type': 'strong_non_responder', 'description': '–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ (-66.7%)'},
            '1807CAA': {'type': 'paradoxical_non_responder', 'description': '–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ (-26.1%)'},
            '1607LVA': {'type': 'stable_non_responder', 'description': '–°—Ç–∞–±–∏–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å (0%)'},
            '1907ZSI': {'type': 'stable_non_responder', 'description': '–°—Ç–∞–±–∏–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å (0%)'},
            '1707DMA': {'type': 'weak_non_responder', 'description': '–õ–µ–≥–∫–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ (-10%)'},
            '1707SAA': {'type': 'weak_non_responder', 'description': '–õ–µ–≥–∫–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ (-9.1%)'},
        }
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.all_participants_stress_data = {**self.stress_responders, **self.stress_non_responders}
        
        print(f"üìä –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –ø–æ —Å—Ç—Ä–µ—Å—Å—É:")
        print(f"   ‚Ä¢ –†–µ—Å–ø–æ–Ω–¥–µ—Ä—ã: {len(self.stress_responders)}")
        print(f"   ‚Ä¢ –ù–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä—ã: {len(self.stress_non_responders)}")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Å—Ç—Ä–µ—Å—Å–µ: {len(self.all_participants_stress_data)}")
    
    def load_eyetracking_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞"""
        print("\nüìÇ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ê–ô–¢–†–ï–ö–ò–ù–ì–ê...")
        
        # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ person_level_analysis.py
        data = pd.read_csv(self.eyetracking_data_path, sep="\t", encoding="utf-16", header=0)
        data = data.iloc[1:].reset_index(drop=True)  # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
        
        print(f"   ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(data)}")
        print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫: {len(data.columns)}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–∞–ø—è—Ç—ã–µ –≤ —Ç–æ—á–∫–∏ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        numeric_columns = [
            'AVERAGE_BLINK_DURATION', 'BLINK_COUNT', 'AVERAGE_FIXATION_DURATION',
            'MEDIAN_FIXATION_DURATION', 'SD_FIXATION_DURATION', 'FIXATION_DURATION_MAX',
            'FIXATION_DURATION_MIN', 'FIXATION_COUNT', 'AVERAGE_SACCADE_AMPLITUDE',
            'MEDIAN_SACCADE_AMPLITUDE', 'SD_SACCADE_AMPLITUDE', 'SACCADE_COUNT',
            'DURATION', 'PUPIL_SIZE_MAX', 'PUPIL_SIZE_MEAN', 'PUPIL_SIZE_MIN',
            'VISITED_INTEREST_AREA_COUNT', 'IA_COUNT', 'RUN_COUNT', 'SAMPLE_COUNT'
        ]
        
        for col in numeric_columns:
            if col in data.columns:
                data[col] = pd.to_numeric(
                    data[col].astype(str).str.replace(",", "."), errors="coerce"
                )
        
        data['INDEX'] = pd.to_numeric(data['INDEX'], errors='coerce')
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        print("   ‚Ä¢ –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫...")
        
        # 1. –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –æ–¥–Ω–æ —Å–ª–æ–≤–æ (–º—Å/—Å–ª–æ–≤–æ)
        data['DURATION_PER_WORD'] = data['DURATION'] / data['IA_COUNT']
        
        # 2. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–∫—Å–∞—Ü–∏–π –Ω–∞ –æ–¥–Ω–æ —Å–ª–æ–≤–æ
        data['FIXATIONS_PER_WORD'] = data['FIXATION_COUNT'] / data['IA_COUNT']
        
        # 3. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–∫–∫–∞–¥ –Ω–∞ –æ–¥–Ω–æ —Å–ª–æ–≤–æ
        data['SACCADES_PER_WORD'] = data['SACCADE_COUNT'] / data['IA_COUNT']
        
        # 4. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ—Ä–≥–∞–Ω–∏–π –Ω–∞ –æ–¥–Ω–æ —Å–ª–æ–≤–æ
        data['BLINKS_PER_WORD'] = data['BLINK_COUNT'] / data['IA_COUNT']
        
        # 5. –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–∫—Å—Ç–∞ (% –ø–æ—Å–µ—â–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞)
        data['TEXT_COVERAGE_PERCENT'] = (data['VISITED_INTEREST_AREA_COUNT'] / data['IA_COUNT']) * 100
        
        # 6. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ—Å–µ—â–µ–Ω–∏–π —Å–ª–æ–≤
        data['REVISITED_WORDS'] = data['RUN_COUNT'] - data['VISITED_INTEREST_AREA_COUNT']
        data['REVISITED_WORDS_PERCENT'] = (data['REVISITED_WORDS'] / data['IA_COUNT']) * 100
        
        # 7. –ß–∞—Å—Ç–æ—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–≤ —Å–µ–∫—É–Ω–¥—É)
        data['FIXATIONS_PER_SECOND'] = data['FIXATION_COUNT'] / (data['DURATION'] / 1000)
        data['SACCADES_PER_SECOND'] = data['SACCADE_COUNT'] / (data['DURATION'] / 1000)
        data['BLINKS_PER_SECOND'] = data['BLINK_COUNT'] / (data['DURATION'] / 1000)
        
        # 8. –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã—Ö —Å–∞–∫–∫–∞–¥
        data['REGRESSIVE_SACCADES'] = data['INTEREST_AREA_FIXATION_SEQUENCE'].apply(self._count_regressive_saccades)
        data['REGRESSIVE_SACCADES_PER_WORD'] = data['REGRESSIVE_SACCADES'] / data['IA_COUNT']
        data['REGRESSIVE_SACCADES_PER_SECOND'] = data['REGRESSIVE_SACCADES'] / (data['DURATION'] / 1000)
        data['REGRESSIVE_SACCADES_PERCENT'] = (data['REGRESSIVE_SACCADES'] / data['SACCADE_COUNT']) * 100
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é —Å—Ç—Ä–µ—Å—Å–∞
        print("   ‚Ä¢ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å—Ç—Ä–µ—Å—Å–∞...")
        data = self._add_stress_classification(data)
        
        print(f"   ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {data['RECORDING_SESSION_LABEL'].nunique()}")
        print(f"   ‚Ä¢ –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Å—Ç—Ä–µ—Å—Å–µ: {len(data[data['stress_group'].notna()])}")
        print(f"   ‚Ä¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥—Ä—É–ø–ø–∞–º —Å—Ç—Ä–µ—Å—Å–∞:")
        print(data['stress_group'].value_counts().to_string())
        
        return data
    
    def _count_regressive_saccades(self, sequence_data):
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã—Ö —Å–∞–∫–∫–∞–¥"""
        if pd.isna(sequence_data) or sequence_data == '.' or sequence_data == '':
            return 0
        
        try:
            if isinstance(sequence_data, list):
                sequence = sequence_data
            else:
                sequence_str = str(sequence_data).strip('[]')
                sequence = [int(x.strip()) for x in sequence_str.split(',') if x.strip().isdigit()]
            
            if len(sequence) < 2:
                return 0
            
            regressive_count = 0
            visited_positions = set()
            
            for current_word in sequence:
                if current_word == 0:
                    continue
                    
                if current_word in visited_positions:
                    regressive_count += 1
                else:
                    visited_positions.add(current_word)
            
            return regressive_count
            
        except (ValueError, AttributeError, TypeError):
            return 0
    
    def _add_stress_classification(self, data):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é —Å—Ç—Ä–µ—Å—Å–∞ –∫ –¥–∞–Ω–Ω—ã–º –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞"""
        
        def classify_participant_text(row):
            participant_id = row['RECORDING_SESSION_LABEL']
            text_index = row['INDEX']
            
            if participant_id in self.stress_responders:
                # –î–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ—Ä–æ–≤: —Ç–µ–∫—Å—Ç—ã 4-6 —Å—á–∏—Ç–∞–µ–º —Å—Ç—Ä–µ—Å—Å–æ–≤—ã–º–∏
                if text_index >= 4:
                    return 'actual_stress'
                else:
                    return 'baseline'
            elif participant_id in self.stress_non_responders:
                # –î–ª—è –Ω–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä–æ–≤: –≤—Å–µ —Ç–µ–∫—Å—Ç—ã —Å—á–∏—Ç–∞–µ–º –Ω–µ—Å—Ç—Ä–µ—Å—Å–æ–≤—ã–º–∏
                if text_index >= 4:
                    return 'intended_stress_no_response'
                else:
                    return 'baseline'
            else:
                # –î–ª—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç—Ä–µ—Å—Å–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
                return 'unknown'
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
        data['stress_classification'] = data.apply(classify_participant_text, axis=1)
        
        # –°–æ–∑–¥–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É
        def get_stress_group(row):
            participant_id = row['RECORDING_SESSION_LABEL']
            if participant_id in self.stress_responders:
                return 'stress_responders'
            elif participant_id in self.stress_non_responders:
                return 'stress_non_responders'
            else:
                return 'unknown'
        
        data['stress_group'] = data.apply(get_stress_group, axis=1)
        
        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é —Ç–∏–ø–æ–≤ —Ä–µ—Å–ø–æ–Ω–¥–µ—Ä–æ–≤
        def get_responder_type(row):
            participant_id = row['RECORDING_SESSION_LABEL']
            if participant_id in self.all_participants_stress_data:
                return self.all_participants_stress_data[participant_id]['type']
            else:
                return 'unknown'
        
        data['responder_type'] = data.apply(get_responder_type, axis=1)
        
        return data
    
    def analyze_stress_vs_eyetracking(self, data):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –≤ –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–µ –º–µ–∂–¥—É —Å—Ç—Ä–µ—Å—Å–æ–≤—ã–º–∏ –∏ –Ω–µ—Å—Ç—Ä–µ—Å—Å–æ–≤—ã–º–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏"""
        print("\nüî¨ –ê–ù–ê–õ–ò–ó –†–ê–ó–õ–ò–ß–ò–ô –í –ê–ô–¢–†–ï–ö–ò–ù–ì–ï: –°–¢–†–ï–°–° VS –ù–ï –°–¢–†–ï–°–°...")
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç—ã 4-6, –≥–¥–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–æ—è–≤–ª—è—Ç—å—Å—è —Å—Ç—Ä–µ—Å—Å)
        stress_phase_data = data[data['INDEX'] >= 4].copy()
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –≥—Ä—É–ø–ø—ã
        actual_stress_data = stress_phase_data[stress_phase_data['stress_classification'] == 'actual_stress']
        no_stress_response_data = stress_phase_data[stress_phase_data['stress_classification'] == 'intended_stress_no_response']
        
        print(f"   ‚Ä¢ –£—á–∞—Å—Ç–Ω–∏–∫–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º —Å—Ç—Ä–µ—Å—Å–æ–º (—Ç–µ–∫—Å—Ç—ã 4-6): {len(actual_stress_data)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
        print(f"   ‚Ä¢ –£—á–∞—Å—Ç–Ω–∏–∫–∏ –±–µ–∑ —Å—Ç—Ä–µ—Å—Å–æ–≤–æ–π —Ä–µ–∞–∫—Ü–∏–∏ (—Ç–µ–∫—Å—Ç—ã 4-6): {len(no_stress_response_data)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
        
        # –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        key_measures = [
            'AVERAGE_FIXATION_DURATION', 'FIXATION_COUNT', 'FIXATIONS_PER_WORD',
            'AVERAGE_SACCADE_AMPLITUDE', 'SACCADE_COUNT', 'SACCADES_PER_WORD',
            'AVERAGE_BLINK_DURATION', 'BLINK_COUNT',
            'PUPIL_SIZE_MEAN', 'PUPIL_SIZE_MAX',
            'DURATION_PER_WORD', 'TEXT_COVERAGE_PERCENT',
            'REGRESSIVE_SACCADES', 'REGRESSIVE_SACCADES_PERCENT',
            'FIXATIONS_PER_SECOND', 'SACCADES_PER_SECOND'
        ]
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å
        results = []
        
        for measure in key_measures:
            stress_values = actual_stress_data[measure].dropna()
            no_stress_values = no_stress_response_data[measure].dropna()
            
            if len(stress_values) > 0 and len(no_stress_values) > 0:
                # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç
                try:
                    t_stat, p_value = ttest_ind(stress_values, no_stress_values)
                    test_name = "t-—Ç–µ—Å—Ç"
                except:
                    u_stat, p_value = mannwhitneyu(stress_values, no_stress_values, alternative='two-sided')
                    test_name = "Mann-Whitney U"
                
                # Cohen's d
                pooled_std = np.sqrt(((len(stress_values) - 1) * stress_values.var() + 
                                     (len(no_stress_values) - 1) * no_stress_values.var()) / 
                                    (len(stress_values) + len(no_stress_values) - 2))
                cohens_d = (stress_values.mean() - no_stress_values.mean()) / pooled_std if pooled_std > 0 else 0
                
                # –ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
                if no_stress_values.mean() != 0:
                    percent_change = ((stress_values.mean() - no_stress_values.mean()) / no_stress_values.mean()) * 100
                else:
                    percent_change = 0
                
                result = {
                    'measure': measure,
                    'stress_mean': stress_values.mean(),
                    'stress_std': stress_values.std(),
                    'no_stress_mean': no_stress_values.mean(),
                    'no_stress_std': no_stress_values.std(),
                    'p_value': p_value,
                    'cohens_d': cohens_d,
                    'percent_change': percent_change,
                    'n_stress': len(stress_values),
                    'n_no_stress': len(no_stress_values),
                    'test_name': test_name
                }
                
                results.append(result)
                
                # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                significance = "‚úÖ –ó–ù–ê–ß–ò–ú–û" if p_value < 0.05 else "‚ùå –ù–ï –ó–ù–ê–ß–ò–ú–û"
                effect_size = "–±–æ–ª—å—à–æ–π" if abs(cohens_d) >= 0.8 else "—Å—Ä–µ–¥–Ω–∏–π" if abs(cohens_d) >= 0.5 else "–º–∞–ª—ã–π"
                
                print(f"\n   üìä {measure}:")
                print(f"      –°—Ç—Ä–µ—Å—Å: {stress_values.mean():.2f}¬±{stress_values.std():.2f}")
                print(f"      –ù–µ—Ç —Å—Ç—Ä–µ—Å—Å–∞: {no_stress_values.mean():.2f}¬±{no_stress_values.std():.2f}")
                print(f"      –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {percent_change:+.1f}% | d = {cohens_d:.3f} ({effect_size})")
                print(f"      {test_name}: p = {p_value:.4f} | {significance}")
        
        return results
    
    def create_stress_integrated_visualizations(self, data, analysis_results):
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        print("\nüé® –°–û–ó–î–ê–ù–ò–ï –ì–†–ê–§–ò–ö–û–í –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê...")
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º
        self._create_group_comparison_plot(data)
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ —Ç–µ–∫—Å—Ç–∞–º —Å —É—á–µ—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å—Ç—Ä–µ—Å—Å–∞
        self._create_stress_dynamics_plot(data)
        
        # –ì—Ä–∞—Ñ–∏–∫ 3: –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏
        self._create_stress_heatmap(analysis_results)
        
        # –ì—Ä–∞—Ñ–∏–∫ 4: –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ —Ä–µ—Å–ø–æ–Ω–¥–µ—Ä–æ–≤ vs –Ω–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä–æ–≤
        self._create_individual_trajectories_plot(data)
        
        # –ì—Ä–∞—Ñ–∏–∫ 5: –ê–Ω–∞–ª–∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —á—Ç–µ–Ω–∏—è
        self._create_reading_patterns_analysis(data)
    
    def _create_group_comparison_plot(self, data):
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≥—Ä—É–ø–ø"""
        fig, axes = plt.subplots(3, 4, figsize=(20, 15))
        axes = axes.flatten()
        
        # –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        measures = [
            'AVERAGE_FIXATION_DURATION', 'FIXATIONS_PER_WORD', 'SACCADES_PER_WORD',
            'REGRESSIVE_SACCADES_PERCENT', 'DURATION_PER_WORD', 'TEXT_COVERAGE_PERCENT',
            'PUPIL_SIZE_MEAN', 'AVERAGE_SACCADE_AMPLITUDE', 'BLINKS_PER_SECOND',
            'FIXATIONS_PER_SECOND', 'SACCADES_PER_SECOND', 'REVISITED_WORDS_PERCENT'
        ]
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ç—Ä–µ—Å—Å–æ–≤–æ–π —Ñ–∞–∑—ã (—Ç–µ–∫—Å—Ç—ã 4-6)
        stress_phase_data = data[data['INDEX'] >= 4]
        
        for i, measure in enumerate(measures):
            ax = axes[i]
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è boxplot
            stress_responders_data = stress_phase_data[
                stress_phase_data['stress_group'] == 'stress_responders'
            ][measure].dropna()
            
            non_responders_data = stress_phase_data[
                stress_phase_data['stress_group'] == 'stress_non_responders'
            ][measure].dropna()
            
            if len(stress_responders_data) > 0 and len(non_responders_data) > 0:
                bp = ax.boxplot([non_responders_data, stress_responders_data], 
                              labels=['–ù–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä—ã', '–†–µ—Å–ø–æ–Ω–¥–µ—Ä—ã'],
                              patch_artist=True)
                
                # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º
                bp['boxes'][0].set_facecolor('#3498DB')  # –°–∏–Ω–∏–π –¥–ª—è –Ω–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä–æ–≤
                bp['boxes'][1].set_facecolor('#E74C3C')  # –ö—Ä–∞—Å–Ω—ã–π –¥–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ—Ä–æ–≤
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                try:
                    t_stat, p_value = ttest_ind(non_responders_data, stress_responders_data)
                    ax.text(0.02, 0.98, f'p = {p_value:.3f}', 
                           transform=ax.transAxes, verticalalignment='top',
                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                except:
                    pass
            
            ax.set_title(f"{measure}")
            ax.grid(True, alpha=0.3)
        
        plt.suptitle('üìä –°–†–ê–í–ù–ï–ù–ò–ï –ê–ô–¢–†–ï–ö–ò–ù–ì–ê: –†–ï–°–ü–û–ù–î–ï–†–´ vs –ù–û–ù-–†–ï–°–ü–û–ù–î–ï–†–´ (–¢–ï–ö–°–¢–´ 4-6)', 
                     fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.results_dir / 'stress_group_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def _create_stress_dynamics_plot(self, data):
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –¥–∏–Ω–∞–º–∏–∫–∏ —Å —É—á–µ—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å—Ç—Ä–µ—Å—Å–∞"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        measures = [
            'AVERAGE_FIXATION_DURATION', 'FIXATIONS_PER_WORD', 'REGRESSIVE_SACCADES_PERCENT',
            'DURATION_PER_WORD', 'PUPIL_SIZE_MEAN', 'TEXT_COVERAGE_PERCENT'
        ]
        
        for i, measure in enumerate(measures):
            ax = axes[i]
            
            # –†–µ—Å–ø–æ–Ω–¥–µ—Ä—ã
            responder_data = data[data['stress_group'] == 'stress_responders']
            responder_means = responder_data.groupby('INDEX')[measure].mean()
            responder_stds = responder_data.groupby('INDEX')[measure].std()
            
            # –ù–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä—ã
            non_responder_data = data[data['stress_group'] == 'stress_non_responders']
            non_responder_means = non_responder_data.groupby('INDEX')[measure].mean()
            non_responder_stds = non_responder_data.groupby('INDEX')[measure].std()
            
            # –ì—Ä–∞—Ñ–∏–∫ –¥–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ—Ä–æ–≤
            texts = sorted(responder_means.index)
            ax.plot(texts, [responder_means[t] for t in texts], 
                   'o-', color='#E74C3C', linewidth=3, markersize=8, 
                   label='–†–µ—Å–ø–æ–Ω–¥–µ—Ä—ã (—Ä–µ–∞–ª—å–Ω—ã–π —Å—Ç—Ä–µ—Å—Å)')
            ax.fill_between(texts, 
                           [responder_means[t] - responder_stds[t] for t in texts],
                           [responder_means[t] + responder_stds[t] for t in texts],
                           alpha=0.2, color='#E74C3C')
            
            # –ì—Ä–∞—Ñ–∏–∫ –¥–ª—è –Ω–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä–æ–≤
            ax.plot(texts, [non_responder_means[t] for t in texts], 
                   'o-', color='#3498DB', linewidth=3, markersize=8,
                   label='–ù–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä—ã (–Ω–µ—Ç —Ä–µ–∞–∫—Ü–∏–∏)')
            ax.fill_between(texts, 
                           [non_responder_means[t] - non_responder_stds[t] for t in texts],
                           [non_responder_means[t] + non_responder_stds[t] for t in texts],
                           alpha=0.2, color='#3498DB')
            
            # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
            ax.axvline(x=3.5, color='black', linestyle='--', alpha=0.7)
            ax.text(3.5, ax.get_ylim()[1] * 0.9, '–ò–ù–î–£–ö–¶–ò–Ø\n–°–¢–†–ï–°–°–ê', 
                   ha='center', va='center',
                   bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))
            
            ax.set_title(f"{measure}")
            ax.set_xlabel("–ù–æ–º–µ—Ä —Ç–µ–∫—Å—Ç–∞")
            ax.grid(True, alpha=0.3)
            ax.legend()
            ax.set_xticks(texts)
        
        plt.suptitle('üìà –î–ò–ù–ê–ú–ò–ö–ê –ê–ô–¢–†–ï–ö–ò–ù–ì–ê –ü–û –¢–ï–ö–°–¢–ê–ú: –†–ï–ê–õ–¨–ù–´–ô –°–¢–†–ï–°–° VS –ù–ï–¢ –†–ï–ê–ö–¶–ò–ò', 
                     fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.results_dir / 'stress_dynamics_real.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def _create_stress_heatmap(self, analysis_results):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É —Ä–∞–∑–ª–∏—á–∏–π"""
        # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –¥–ª—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã
        measures = [r['measure'] for r in analysis_results]
        effect_sizes = [r['cohens_d'] for r in analysis_results]
        p_values = [r['p_value'] for r in analysis_results]
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã
        heatmap_data = pd.DataFrame({
            '–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': measures,
            '–†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞ (Cohen\'s d)': effect_sizes,
            'p-–∑–Ω–∞—á–µ–Ω–∏–µ': p_values,
            '–ó–Ω–∞—á–∏–º–æ—Å—Ç—å': ['‚úÖ' if p < 0.05 else '‚ùå' for p in p_values]
        })
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 12))
        
        # –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
        effect_matrix = np.array(effect_sizes).reshape(-1, 1)
        sns.heatmap(effect_matrix, 
                   annot=np.array([[d] for d in effect_sizes]),
                   fmt='.3f',
                   yticklabels=measures,
                   xticklabels=['Cohen\'s d'],
                   cmap='RdBu_r', center=0,
                   ax=ax1, cbar_kws={'label': '–†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞'})
        ax1.set_title('–†–∞–∑–º–µ—Ä—ã —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ (Cohen\'s d)')
        
        # –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ p-–∑–Ω–∞—á–µ–Ω–∏–π
        p_matrix = np.array([-np.log10(p) for p in p_values]).reshape(-1, 1)
        sns.heatmap(p_matrix,
                   annot=np.array([[p] for p in p_values]),
                   fmt='.3f',
                   yticklabels=measures,
                   xticklabels=['-log10(p)'],
                   cmap='viridis',
                   ax=ax2, cbar_kws={'label': '-log10(p-value)'})
        ax2.set_title('–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å')
        ax2.axhline(y=len(measures), color='red', linestyle='--', alpha=0.7)
        
        plt.suptitle('üî• –¢–ï–ü–õ–û–í–ê–Ø –ö–ê–†–¢–ê –†–ê–ó–õ–ò–ß–ò–ô –í –ê–ô–¢–†–ï–ö–ò–ù–ì–ï: –°–¢–†–ï–°–° vs –ù–ï –°–¢–†–ï–°–°', 
                     fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.results_dir / 'stress_effect_heatmap.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def _create_individual_trajectories_plot(self, data):
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        axes = axes.flatten()
        
        key_measures = [
            'AVERAGE_FIXATION_DURATION', 'REGRESSIVE_SACCADES_PERCENT', 
            'DURATION_PER_WORD', 'PUPIL_SIZE_MEAN'
        ]
        
        for i, measure in enumerate(key_measures):
            ax = axes[i]
            
            # –†–µ—Å–ø–æ–Ω–¥–µ—Ä—ã
            for participant in self.stress_responders.keys():
                participant_data = data[data['RECORDING_SESSION_LABEL'] == participant]
                if not participant_data.empty:
                    texts = participant_data['INDEX'].values
                    values = participant_data[measure].values
                    
                    responder_type = self.stress_responders[participant]['type']
                    if 'strong' in responder_type:
                        color, alpha, linewidth = '#C0392B', 0.8, 2.5
                    elif 'moderate' in responder_type:
                        color, alpha, linewidth = '#E74C3C', 0.7, 2
                    else:
                        color, alpha, linewidth = '#F1948A', 0.6, 1.5
                    
                    ax.plot(texts, values, 'o-', 
                           color=color, alpha=alpha, linewidth=linewidth,
                           label=f'–†–µ—Å–ø: {participant}' if i == 0 else "")
            
            # –ù–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä—ã
            for participant in self.stress_non_responders.keys():
                participant_data = data[data['RECORDING_SESSION_LABEL'] == participant]
                if not participant_data.empty:
                    texts = participant_data['INDEX'].values
                    values = participant_data[measure].values
                    
                    ax.plot(texts, values, 's-', 
                           color='#3498DB', alpha=0.7, linewidth=1.5,
                           label=f'–ù–æ–Ω-—Ä–µ—Å–ø: {participant}' if i == 0 else "")
            
            # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏–Ω–∏—è
            ax.axvline(x=3.5, color='black', linestyle='--', alpha=0.7)
            
            ax.set_title(f"{measure}")
            ax.set_xlabel("–ù–æ–º–µ—Ä —Ç–µ–∫—Å—Ç–∞")
            ax.grid(True, alpha=0.3)
            if i == 0:
                ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
        
        plt.suptitle('üë• –ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–´–ï –¢–†–ê–ï–ö–¢–û–†–ò–ò –£–ß–ê–°–¢–ù–ò–ö–û–í', 
                     fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.results_dir / 'individual_trajectories_stress.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def _create_reading_patterns_analysis(self, data):
        """–°–æ–∑–¥–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —á—Ç–µ–Ω–∏—è"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤ 4-6 (—Å—Ç—Ä–µ—Å—Å–æ–≤–∞—è —Ñ–∞–∑–∞)
        stress_data = data[data['INDEX'] >= 4]
        
        # 1. –°–∫–æ—Ä–æ—Å—Ç—å —á—Ç–µ–Ω–∏—è
        ax = axes[0]
        responders = stress_data[stress_data['stress_group'] == 'stress_responders']['DURATION_PER_WORD']
        non_responders = stress_data[stress_data['stress_group'] == 'stress_non_responders']['DURATION_PER_WORD']
        
        ax.hist([responders.dropna(), non_responders.dropna()], 
               bins=15, alpha=0.7, label=['–†–µ—Å–ø–æ–Ω–¥–µ—Ä—ã', '–ù–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä—ã'],
               color=['#E74C3C', '#3498DB'])
        ax.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ —á—Ç–µ–Ω–∏—è')
        ax.set_xlabel('–í—Ä–µ–º—è –Ω–∞ —Å–ª–æ–≤–æ (–º—Å)')
        ax.legend()
        
        # 2. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —á—Ç–µ–Ω–∏—è
        ax = axes[1]
        responder_coverage = stress_data[stress_data['stress_group'] == 'stress_responders']['TEXT_COVERAGE_PERCENT']
        non_responder_coverage = stress_data[stress_data['stress_group'] == 'stress_non_responders']['TEXT_COVERAGE_PERCENT']
        
        ax.boxplot([non_responder_coverage.dropna(), responder_coverage.dropna()],
                  labels=['–ù–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä—ã', '–†–µ—Å–ø–æ–Ω–¥–µ—Ä—ã'])
        ax.set_title('–ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–∫—Å—Ç–∞')
        ax.set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤')
        
        # 3. –í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã
        ax = axes[2]
        resp_regressive = stress_data[stress_data['stress_group'] == 'stress_responders']['REGRESSIVE_SACCADES_PERCENT']
        non_resp_regressive = stress_data[stress_data['stress_group'] == 'stress_non_responders']['REGRESSIVE_SACCADES_PERCENT']
        
        ax.scatter(responders.dropna(), resp_regressive.dropna(), 
                  alpha=0.6, color='#E74C3C', s=60, label='–†–µ—Å–ø–æ–Ω–¥–µ—Ä—ã')
        ax.scatter(non_responders.dropna(), non_resp_regressive.dropna(), 
                  alpha=0.6, color='#3498DB', s=60, label='–ù–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä—ã')
        ax.set_xlabel('–í—Ä–µ–º—è –Ω–∞ —Å–ª–æ–≤–æ (–º—Å)')
        ax.set_ylabel('–í–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ —Å–∞–∫–∫–∞–¥—ã (%)')
        ax.set_title('–°–≤—è–∑—å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –≤–æ–∑–≤—Ä–∞—Ç–Ω—ã—Ö —Å–∞–∫–∫–∞–¥')
        ax.legend()
        
        # 4. –†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞ vs –≤–Ω–∏–º–∞–Ω–∏–µ
        ax = axes[3]
        resp_pupil = stress_data[stress_data['stress_group'] == 'stress_responders']['PUPIL_SIZE_MEAN']
        resp_fixations = stress_data[stress_data['stress_group'] == 'stress_responders']['FIXATIONS_PER_WORD']
        non_resp_pupil = stress_data[stress_data['stress_group'] == 'stress_non_responders']['PUPIL_SIZE_MEAN']
        non_resp_fixations = stress_data[stress_data['stress_group'] == 'stress_non_responders']['FIXATIONS_PER_WORD']
        
        ax.scatter(resp_pupil.dropna(), resp_fixations.dropna(), 
                  alpha=0.6, color='#E74C3C', s=60, label='–†–µ—Å–ø–æ–Ω–¥–µ—Ä—ã')
        ax.scatter(non_resp_pupil.dropna(), non_resp_fixations.dropna(), 
                  alpha=0.6, color='#3498DB', s=60, label='–ù–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä—ã')
        ax.set_xlabel('–†–∞–∑–º–µ—Ä –∑—Ä–∞—á–∫–∞ (—É.–µ.)')
        ax.set_ylabel('–§–∏–∫—Å–∞—Ü–∏–∏ –Ω–∞ —Å–ª–æ–≤–æ')
        ax.set_title('–°–≤—è–∑—å –∑—Ä–∞—á–∫–∞ –∏ –≤–Ω–∏–º–∞–Ω–∏—è')
        ax.legend()
        
        # 5. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏
        ax = axes[4]
        for text_idx in [4, 5, 6]:
            text_data = stress_data[stress_data['INDEX'] == text_idx]
            resp_duration = text_data[text_data['stress_group'] == 'stress_responders']['DURATION_PER_WORD'].mean()
            non_resp_duration = text_data[text_data['stress_group'] == 'stress_non_responders']['DURATION_PER_WORD'].mean()
            
            ax.bar([f'T{text_idx}_–†–µ—Å–ø', f'T{text_idx}_–ù–æ–Ω–†–µ—Å–ø'], 
                  [resp_duration, non_resp_duration],
                  color=['#E74C3C', '#3498DB'], alpha=0.7)
        
        ax.set_title('–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏ –ø–æ —Ç–µ–∫—Å—Ç–∞–º')
        ax.set_ylabel('–í—Ä–µ–º—è –Ω–∞ —Å–ª–æ–≤–æ (–º—Å)')
        plt.setp(ax.get_xticklabels(), rotation=45)
        
        # 6. –°–≤–æ–¥–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ —Å—Ç—Ä–µ—Å—Å–∞
        ax = axes[5]
        # –°–æ–∑–¥–∞–µ–º —Å–æ—Å—Ç–∞–≤–Ω–æ–π –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–µ—Å—Å–∞ –¥–ª—è –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞
        stress_data_clean = stress_data.dropna(subset=['DURATION_PER_WORD', 'REGRESSIVE_SACCADES_PERCENT', 'FIXATIONS_PER_WORD'])
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏ —Å–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å
        normalized_duration = (stress_data_clean['DURATION_PER_WORD'] - stress_data_clean['DURATION_PER_WORD'].mean()) / stress_data_clean['DURATION_PER_WORD'].std()
        normalized_regressive = (stress_data_clean['REGRESSIVE_SACCADES_PERCENT'] - stress_data_clean['REGRESSIVE_SACCADES_PERCENT'].mean()) / stress_data_clean['REGRESSIVE_SACCADES_PERCENT'].std()
        normalized_fixations = (stress_data_clean['FIXATIONS_PER_WORD'] - stress_data_clean['FIXATIONS_PER_WORD'].mean()) / stress_data_clean['FIXATIONS_PER_WORD'].std()
        
        eyetracking_stress_index = normalized_duration + normalized_regressive + normalized_fixations
        stress_data_clean['eyetracking_stress_index'] = eyetracking_stress_index
        
        resp_index = stress_data_clean[stress_data_clean['stress_group'] == 'stress_responders']['eyetracking_stress_index']
        non_resp_index = stress_data_clean[stress_data_clean['stress_group'] == 'stress_non_responders']['eyetracking_stress_index']
        
        ax.boxplot([non_resp_index.dropna(), resp_index.dropna()],
                  labels=['–ù–æ–Ω-—Ä–µ—Å–ø–æ–Ω–¥–µ—Ä—ã', '–†–µ—Å–ø–æ–Ω–¥–µ—Ä—ã'])
        ax.set_title('–°–æ—Å—Ç–∞–≤–Ω–æ–π –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–µ—Å—Å–∞ (–∞–π—Ç—Ä–µ–∫–∏–Ω–≥)')
        ax.set_ylabel('–ò–Ω–¥–µ–∫—Å —Å—Ç—Ä–µ—Å—Å–∞ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π)')
        
        plt.suptitle('üìñ –ê–ù–ê–õ–ò–ó –°–ü–ï–¶–ò–§–ò–ß–ï–°–ö–ò–• –ü–ê–¢–¢–ï–†–ù–û–í –ß–¢–ï–ù–ò–Ø –ü–†–ò –°–¢–†–ï–°–°–ï', 
                     fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.results_dir / 'reading_patterns_stress.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_integrated_report(self, analysis_results):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç"""
        print("\nüìã –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–û–ì–û –û–¢–ß–ï–¢–ê...")
        print("=" * 60)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É —ç—Ñ—Ñ–µ–∫—Ç–∞
        sorted_results = sorted(analysis_results, key=lambda x: abs(x['cohens_d']), reverse=True)
        
        print(f"üèÜ –¢–û–ü-10 –ü–û–ö–ê–ó–ê–¢–ï–õ–ï–ô –ê–ô–¢–†–ï–ö–ò–ù–ì–ê, –†–ê–ó–õ–ò–ß–ê–Æ–©–ò–• –°–¢–†–ï–°–°:")
        for i, result in enumerate(sorted_results[:10], 1):
            significance = "‚úÖ" if result['p_value'] < 0.05 else "‚ùå"
            effect_size = ("–±–æ–ª—å—à–æ–π" if abs(result['cohens_d']) >= 0.8 else 
                          "—Å—Ä–µ–¥–Ω–∏–π" if abs(result['cohens_d']) >= 0.5 else "–º–∞–ª—ã–π")
            
            print(f"   {i:2d}. {result['measure']}")
            print(f"       –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∏ —Å—Ç—Ä–µ—Å—Å–µ: {result['percent_change']:+.1f}%")
            print(f"       –†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞: d = {result['cohens_d']:.3f} ({effect_size})")
            print(f"       –ó–Ω–∞—á–∏–º–æ—Å—Ç—å: p = {result['p_value']:.4f} {significance}")
            print()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º
        significant_results = [r for r in analysis_results if r['p_value'] < 0.05]
        large_effects = [r for r in analysis_results if abs(r['cohens_d']) >= 0.8]
        
        print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ê–Ø –°–í–û–î–ö–ê:")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π: {len(analysis_results)}")
        print(f"   ‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ä–∞–∑–ª–∏—á–∏–π: {len(significant_results)} ({len(significant_results)/len(analysis_results)*100:.1f}%)")
        print(f"   ‚Ä¢ –ü–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å –±–æ–ª—å—à–∏–º —Ä–∞–∑–º–µ—Ä–æ–º —ç—Ñ—Ñ–µ–∫—Ç–∞: {len(large_effects)}")
        
        # –ê–Ω–∞–ª–∏–∑ –≥—Ä—É–ø–ø —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
        print(f"\nüë• –ê–ù–ê–õ–ò–ó –£–ß–ê–°–¢–ù–ò–ö–û–í:")
        print(f"   üìà –†–ï–°–ü–û–ù–î–ï–†–´ (—Ä–µ–∞–≥–∏—Ä–æ–≤–∞–ª–∏ –Ω–∞ —Å—Ç—Ä–µ—Å—Å):")
        for participant_id, info in self.stress_responders.items():
            print(f"      ‚Ä¢ {participant_id}: {info['description']}")
        
        print(f"\n   üìâ –ù–û–ù-–†–ï–°–ü–û–ù–î–ï–†–´ (–Ω–µ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–ª–∏ –Ω–∞ —Å—Ç—Ä–µ—Å—Å):")
        for participant_id, info in self.stress_non_responders.items():
            print(f"      ‚Ä¢ {participant_id}: {info['description']}")
        
        # –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print(f"\nüí° –ì–õ–ê–í–ù–´–ï –í–´–í–û–î–´:")
        if len(significant_results) > len(analysis_results) * 0.3:
            print(f"   ‚úÖ –ê–π—Ç—Ä–µ–∫–∏–Ω–≥ –≠–§–§–ï–ö–¢–ò–í–ï–ù –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å—Ç—Ä–µ—Å—Å–∞")
            print(f"   ‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –≤ {len(significant_results)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö")
        else:
            print(f"   ‚ö†Ô∏è  –ê–π—Ç—Ä–µ–∫–∏–Ω–≥ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –û–ì–†–ê–ù–ò–ß–ï–ù–ù–£–Æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å")
            print(f"   ‚ö†Ô∏è  –ù–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
        
        print(f"\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –î–ï–¢–ï–ö–¶–ò–ò –°–¢–†–ï–°–°–ê:")
        if large_effects:
            print(f"   üìä –§–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö —Å –±–æ–ª—å—à–∏–º–∏ —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏:")
            for result in large_effects[:3]:
                print(f"      ‚Ä¢ {result['measure']}: {result['percent_change']:+.1f}% –∏–∑–º–µ–Ω–µ–Ω–∏–µ")
        
        print(f"   üî¨ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞ –∏ —Ñ–∏–∑–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
        print(f"   üìà –£—á–∏—Ç—ã–≤–∞—Ç—å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
        
        print("=" * 60)
    
    def run_integrated_analysis(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        print("üî¨ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô –ê–ù–ê–õ–ò–ó: –°–¢–†–ï–°–° (–ü–û–õ–ò–ì–†–ê–§) + –ê–ô–¢–†–ï–ö–ò–ù–ì")
        print("=" * 70)
        
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞–π—Ç—Ä–µ–∫–∏–Ω–≥–∞
        eyetracking_data = self.load_eyetracking_data()
        
        # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏
        analysis_results = self.analyze_stress_vs_eyetracking(eyetracking_data)
        
        # 3. –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        self.create_stress_integrated_visualizations(eyetracking_data, analysis_results)
        
        # 4. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        self.generate_integrated_report(analysis_results)
        
        print(f"\n‚úÖ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.results_dir}")
        print(f"üé® –°–æ–∑–¥–∞–Ω–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤: 5")
        print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π: {len(analysis_results)}")
        
        return {
            'eyetracking_data': eyetracking_data,
            'analysis_results': analysis_results,
            'stress_classification': self.all_participants_stress_data
        }


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üëÅÔ∏è  –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –°–¢–†–ï–°–°–ê –ò –ê–ô–¢–†–ï–ö–ò–ù–ì–ê")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = IntegratedStressEyetrackingAnalyzer()
    results = analyzer.run_integrated_analysis()
    
    return results


if __name__ == "__main__":
    main() 